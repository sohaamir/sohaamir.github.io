<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://sohaamir.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://sohaamir.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-09-09T23:19:56+00:00</updated><id>https://sohaamir.github.io/feed.xml</id><title type="html">Aamir Sohail üá¨üáß üáµüá∞</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">When knowing about cognitive neuroscience can make you a millionaire</title><link href="https://sohaamir.github.io/blog/2025/millionaire/" rel="alternate" type="text/html" title="When knowing about cognitive neuroscience can make you a millionaire"/><published>2025-09-05T15:35:00+00:00</published><updated>2025-09-05T15:35:00+00:00</updated><id>https://sohaamir.github.io/blog/2025/millionaire</id><content type="html" xml:base="https://sohaamir.github.io/blog/2025/millionaire/"><![CDATA[<p>Who Wants to Be a Millionaire? (WWTBAM), is arguably the most famous gameshow of the early to mid-2000‚Äôs. Beginning in 1998 on UK television, it quickly became a cultural hit, spreading internationally with many adaptations. For those unfamiliar with the show, contestants must answer <b>15 trivia questions, each with four possible answers, one right and three wrong.</b> They may choose to walk away at any point, otherwise if they choose to answer and are wrong, they fall back to the most recent checkpoint (1,000 or 32,000<sup>1</sup>. To help them along the way, contestants have three lifelines</p> <ol> <li><b>Ask the Audience</b> (where the audience is polled who each provide their guess on which answer is correct)</li> <li><b>50:50</b> (where you can choose to remove two of the options)</li> <li><b>Phone a Friend</b> (where you have 30 seconds to talk with a friend who can advise you on making your choice)</li> </ol> <div style="text-align: center;"> <img src="/assets/img/posts/millionaire/moneytree.png" alt="moneytree" width="250"/> <p style="margin-top: 10px; color: #555; font-size: 20px; text-align: center;"> The classic Millionaire moneytree - example taken from UK Millionaire (1998) </p> </div> <p>Whilst only requiring 15 answers to win the top prize of 1 million, this has proven particularly difficult to achieve, with only 6 winners recorded on the British Millionaire, and 15 in the US adaptation over thousands of episodes across 25 years<sup>2</sup>.</p> <h2 id="million-plus-questions">Million-plus questions</h2> <p>But despite the moniker, there have been a few occasions where contestants could actually win more than a million. For a while in the ‚ÄòPrimetime‚Äô version of US Millionaire for example, the jackpot accumulated by $10,000 for each episode where there was no winner. Subsequently, there were four instances where a contestant made it to the final question, and was faced with a question worth more than 1 million.</p> <p>Gary Gambino was the first, facing a question for exactly $2 million on March 1, 2001:</p> <p><b>‚ÄúWho is the only winner of the Nobel Peace Prize to decline the prize?‚Äù</b></p> <p>(A) Albert Schweitzer</p> <p>(B) Le Duc Tho</p> <p>(C) Andrei Sakharov</p> <p>(D) Aung San Suu Kyi</p> <p>Gary did not know and decided to walk away with $500,000.</p> <p>A month - and 14 episodes later - on April 1st, David Stewart faced a question for $2.14 million:</p> <p><b>‚ÄúPeople who have a marked physical reaction to beautiful art are said to suffer from what syndrome?‚Äù</b></p> <p>(A) Proust Syndrome</p> <p>(B) Jerusalem Syndrome</p> <p>(C) Stendhal‚Äôs Syndrome</p> <p>(D) Beckett‚Äôs Syndrome</p> <p>David actually still had two lifelines to use: ‚ÄòAsk the Audience‚Äô and ‚ÄòPhone a Friend‚Äô. Asking the audience didn‚Äôt help much, as you might expect for such a difficult question - as they were split quite evenly 26%, 15%, 32% and 27% across the four options. He decided to phone a friend, but faced a dilemma, one was an artist and the other a psychologist! His decision to go with the psychologist was unfortunately not vindicated as they had no idea! He ultimately also decided to walk away with the $500,000.</p> <p>Just nine days later, on April 10, Kevin Olmstead became the third, the jackpot now worth $2.18 million. Here is the question he faced:</p> <p><b>‚ÄúWho is credited with inventing the first mass-produced helicopter?‚Äù</b></p> <p>(A) Igor Sikorsky</p> <p>(B) Elmer Sperry</p> <p>(C) Ferdinand von Zeppelin</p> <p>(D) Gottlieb Daimler</p> <p>He immediately knew the answer and answered correctly, becoming the single largest winner in gameshow history up until that point (he would later be overtaken by Jeopardy titan Ken Jennings).</p> <div style="text-align: center;"> <img src="/assets/img/posts/millionaire/olmstead_wins.jpg" alt="olmstead" width="500"/> <p style="margin-top: 10px; color: #555; font-size: 20px; text-align: center;"> Realising that you've just won $1 million </p> </div> <p>After Kevin‚Äôs win, no one reached the million+ dollar question for 5 months. It was only until September 7, 2001 where Ed Toutant became the fourth and final contestant. He was given this question for $1.86 million:</p> <p><b>‚ÄúDuring WWII, U.S. soldiers used the first commercial aerosol cans to hold what?‚Äù</b></p> <p>(A) Cleaning fluid</p> <p>(B) Antiseptic</p> <p>(C) Insecticide</p> <p>(D) Shaving cream</p> <p>Ed used his 50:50 before ultimately choosing the correct answer. His run - apart from being the final case where a player won more than a million on WWTBAM - was memorable for another reason. He was originally a contestant in January of that year, where the jackpot was $1.86 million (having not yet been won by Kevin Olmstead). He was playing for $16,000 with the following question:</p> <p><b>‚ÄúScientists in England recently genetically altered what vegetable so it glows when it needs water?‚Äù</b></p> <p>(A) Potato</p> <p>(B) Tomato</p> <p>(C) Cabbage</p> <p>(D) Carrots</p> <p>After asking the audience, who voted 64% for Tomato, he decided to go with that as the answer. However, they was wrong, the correct answer was Potato. That seemed to be that, but after doing some research he discovered a few things that could dispute the question entirely:</p> <ul> <li>The experiment had actually been done in Scotland, not England</li> <li>There was ongoing research with doing the same in tomatoes</li> </ul> <p>As a result, he contacted the producers of the show, who agreed that he should be invited back. When he finally played again, he not only started back where he was at $8,000 (rather than starting from the beginning), he was re-awarded his ‚ÄòAsk the Audience‚Äô lifeline, and the jackpot was restored to $1.86 million, which is what he was playing for at the time of his original run. Who would have thought that he would end up winning!</p> <h2 id="flawed-questions">Flawed questions</h2> <p>This brings us into the curious scenario of flawed questions. The questions on WWTBAM are often set by trivia experts who - most of the time - are able to provide clear questions, with 3 definitively wrong and 1 definitively right answer. <b>But this isn‚Äôt always the case.</b> Whilst Ed‚Äôs is one of the more well-known examples, there are plenty of other cases where the question was subsequently challenged.</p> <p>There are also different categories of flawed questions, including questions with multiple correct answers and questions with no correct answers! Here are some examples.</p> <p>In the Austrian adaptation of Millionaire, contestant Peter Prinz in March 2002, for ‚Ç¨15,000, was asked:</p> <p><b>‚ÄúWho won a silver medal in swimming at the Olympic Games in 1952?‚Äù </b></p> <p>(A) Johnny Weissm√ºller</p> <p>(B) Bud Spencer</p> <p>(C) Gunther Philipp</p> <p>(D) Bruno Kreisky</p> <p>After choosing (A) incorrectly (the correct answer was Bud Spencer), Peter decided to learn more about the topic after the show. It transpired that Spencer had reached the semi-final of the 100m freestyle but did not win a silver medal in 1952, with Hiroshi Suzuki winning it instead!</p> <p>In the UK version, Laurence and Jackie Llewelyn Bowen - playing as a duo in February 2006, had actually made it all the way to the ¬£1 million question, where they were asked:</p> <p><b>‚ÄúTranslated from the Latin, what is the motto of the United States?‚Äù</b></p> <p>(A) In God we trust</p> <p>(B) One out of many</p> <p>(C) All as one</p> <p>(D) Striving together</p> <p>Choosing to answer (A), they were horrified to be told that the correct answer was (B). However, it was later clarified that whilst ‚ÄúOne out of many‚Äù was indeed the original motto of the United States, having Latin origins (E pluribus unum), but since 1956, the US were also using ‚ÄúIn God we trust,‚Äù as a national motto, which did not have Latin origins. They were ultimately invited back, and faced another million-pound question, which they ultimately decided to walk away from.</p> <div style="text-align: center;"> <img src="/assets/img/posts/millionaire/llewelyn_bowen.png" alt="bowen" width="600"/> <p style="margin-top: 10px; color: #555; font-size: 20px; text-align: center;"> Realising that you've just lost ¬£468,000 </p> </div> <p>Speaking of questions with more than one correct answer, also on the British version of Millionaire, on September 8, 2001, Stephen Parker faced this question for ¬£64,000:</p> <p><b>‚ÄúWhat was the middle name of 18th century-born playwright Richard Sheridan?‚Äù </b></p> <p>(A) Brinsley</p> <p>(B) Butler</p> <p>(C) Blake</p> <p>(D) Boynton</p> <p>Stephen answered (B), but it was revealed that the correct answer was (A). As a result, Stephen left with ¬£32,000. However, it turns out that Richard Sheridan‚Äôs full name was<b> Richard Brinsley Butler Sheridan!</b> He was invited back a month later, and was actually allowed to continue playing from ¬£64,000, accepting his original answer as being correct. He walked away on the next question.</p> <p>The Llewelyn Bowen and Parker questions are both examples where multiple options could have been accepted as correct, due to the vagueness of the question. In these and other cases, the ambiguity of the question was acknowledged, with the contestant being invited back soon after. However, there is one specific example for which this was not acknowledged at the time, and is still yet to be over twenty years later.</p> <h2 id="super-millionaire-and-the-flawed-million-dollar-question">‚ÄòSuper Millionaire‚Äô and the flawed Million Dollar Question</h2> <p>In 2004, the US adaptation of Millionaire introduced a more extravagant version of the classic game. ‚ÄòWho Wants to Be a Super Millionaire‚Äô (shortened to ‚ÄòSuper Millionaire‚Äô) was a short-lived version where contestants now played for an ultimate prize of <b>$10 million</b> rather than the usual low-stakes of $1 million. The general format still remained, with 15 questions now separating you from a SEVEN-figure payout.</p> <table> <thead> <tr> <th>Question No.</th> <th style="text-align: center">Correct Answer Value</th> <th style="text-align: center">Amount Lost for a Wrong Answer</th> </tr> </thead> <tbody> <tr> <td>15</td> <td style="text-align: center">$10,000,000</td> <td style="text-align: center">$4,900,000</td> </tr> <tr> <td>14</td> <td style="text-align: center">$5,000,000</td> <td style="text-align: center">$2,400,000</td> </tr> <tr> <td>13</td> <td style="text-align: center">$2,500,000</td> <td style="text-align: center">$900,000</td> </tr> <tr> <td>12</td> <td style="text-align: center">$1,000,000</td> <td style="text-align: center">$400,000</td> </tr> <tr> <td>11</td> <td style="text-align: center">$500,000</td> <td style="text-align: center">$0</td> </tr> <tr> <td>10</td> <td style="text-align: center">$100,000</td> <td style="text-align: center">$45,000</td> </tr> <tr> <td>9</td> <td style="text-align: center">$50,000</td> <td style="text-align: center">$25,000</td> </tr> <tr> <td>8</td> <td style="text-align: center">$30,000</td> <td style="text-align: center">$15,000</td> </tr> <tr> <td>7</td> <td style="text-align: center">$20,000</td> <td style="text-align: center">$5,000</td> </tr> <tr> <td>6</td> <td style="text-align: center">$10,000</td> <td style="text-align: center">$0</td> </tr> <tr> <td>5</td> <td style="text-align: center">$5,000</td> <td style="text-align: center">$4,000</td> </tr> <tr> <td>4</td> <td style="text-align: center">$4,000</td> <td style="text-align: center">$3,000</td> </tr> <tr> <td>3</td> <td style="text-align: center">$3,000</td> <td style="text-align: center">$2,000</td> </tr> <tr> <td>2</td> <td style="text-align: center">$2,000</td> <td style="text-align: center">$1,000</td> </tr> <tr> <td>1</td> <td style="text-align: center">$1,000</td> <td style="text-align: center">$0</td> </tr> </tbody> </table> <p><br/></p> <p>However, the questions were noticeably more difficult. To help out, an extra two lifelines were introduced, but only made available if contestants reached the $100,000 mark (question 10).</p> <ul> <li><b>Double Dip</b> where players could make two choices instead of only one. However, contestants would have to commit to the question if deciding to use it.</li> <li><b>The Three Wise Men</b>, a panel of three experts similar to ‚ÄòPhone a Friend‚Äô where they would have 30 seconds to advise the contestant on which answer to choose</li> </ul> <p>You may have realised that ‚Äì in theory - a contestant could guarantee a correct answer by using both the 50:50 and Double Dip lifelines on the same question! Whilst it was brought up during the episodes, this never in fact happened.</p> <p>There were only 12 episodes of Super Millionaire, with 31 contestants taking part. <b>Of those 31, just 5 saw a million-dollar question.</b> But before jumping into the case of the flawed million-dollar question, it is worth revisiting the run of one of the other 5.</p> <p>I had mentioned above that only four people had the opportunity to answer a question which would have won then more than the million-dollar jackpot:</p> <ol> <li> <p>Gary Gambino ($2.00 million) ‚Äì March 1, 2001</p> </li> <li> <p>David Stewart ($2.14 million) ‚Äì April 1, 2001</p> </li> <li> <p>Kevin Olmstead ($2.18 million) ‚Äì April 10, 2001</p> </li> <li> <p>Ed Toutant ($1.86 million) ‚Äì September 7, 2001</p> </li> </ol> <p>However, there was actually a 5th instance, when Robert ‚ÄòBob-O‚Äô Essig became the first - and only player - to win a million dollars on Super Millionaire. After doing so, he faced a question for <b>$2.5 million:</b></p> <p><b>‚ÄúThe last known sighting of labor leader Jimmy Hoffa was on July 30, 1975 at what Michigan restaurant‚Äôs parking lot?‚Äù</b></p> <p>(A) Machus Red Fox</p> <p>(B) Big Daddy‚Äôs Parthenon</p> <p>(C) Beau Jacks Restaurant</p> <p>(D) Salvatore Scallopini</p> <p>Bob ultimately didn‚Äôt know the answer and decided to walk away with the million. It‚Äôs interesting to know what the questions for the $5 million and $10 million would have been, but we may never know! Bob was only the second player to take part in Super Millionaire, so you would be forgiven for thinking that at least one person would have gone further, or even all the way!</p> <p>Bob had followed the first contestant on Super Millionaire, Todd Kim. Todd was a law graduate, earning both his BA and JD from Harvard and was an executive editor of the Harvard Law Review. And as the very first contestant, no one quite knew what to expect from his run, but he seemed to be doing pretty well. In fact, he didn‚Äôt use a single lifeline on his first 8 questions. However, on Question 9 (for $50,000) he used his 50/50 and in the very next question (for $100,000) burned through the ‚ÄòAsk the Audience‚Äô and ‚ÄòPhone a Friend‚Äô lifelines.</p> <p><br/></p> <div style="text-align: center;"> <img src="/assets/img/posts/millionaire/kim_moneytree.jpg" alt="kim Money" width="600"/> <p style="margin-top: 10px; color: #555; font-size: 20px; text-align: center;"> Todd Kim preparing to be the first contestant on Super Millionaire </p> </div> <p>But Todd had made it to the second checkpoint, and was now guaranteed at least $100,000. Answering just one more question would increase this 5-fold. However, this question was particularly fiendish:</p> <p><b>‚ÄúThe first condom commercial to air on network TV ran in 1991 during the broadcast of what TV series?‚Äù</b></p> <p>(A) Nurses</p> <p>(B) Anything But Love</p> <p>(C) Herman‚Äôs Head</p> <p>(D) Get a Life</p> <p>Todd didn‚Äôt know and used his newly acquired ‚ÄòThree Wise Men‚Äô lifeline (as he had just reached the $100,000 checkpoint). The wise men consisted of author Anthony DeCurtis, astrophysicist Neil deGrasse Tyson and previous Millionaire winner Nancy Christy. They weren‚Äôt sure but ultimately advised Todd on a particular answer. Todd then used his Double Dip, and whilst getting the first guess wrong, the second one was right.</p> <p><br/></p> <div style="text-align: center;"> <img src="/assets/img/posts/millionaire/kim_three_wise_men.jpg" alt="Three Wise Men" width="600"/> <p style="margin-top: 10px; color: #555; font-size: 20px; text-align: center;"> Todd's 'Three Wise Men' - Anthony DeCurtis, Neil deGrasse Tyson and Nancy Christy </p> </div> <p>He then faced a question for $1 million, being the first person to play for a million on Super Millionaire, already as the first contestant:</p> <p><b>‚ÄúNeurologists believe that the brain‚Äôs medial ventral prefrontal cortex is activated when you do what?‚Äù</b></p> <p>(A) Have a panic attack</p> <p>(B) Remember a name</p> <p>(C) Get a joke</p> <p>(D) Listen to music</p> <p>Todd had no idea - unsurprisingly - the ventromedial prefrontal cortex (vmPFC) is a region of the brain only psychologists and neuroscientists would even know the name of, never mind the function. He decided to eventually walk away with the $500,000.</p> <div style="text-align: center;"> <img src="/assets/img/posts/millionaire/kim_vmpfc.png" alt="Kim vmPFC" width="600"/> <p style="margin-top: 10px; color: #555; font-size: 20px; text-align: center;"> When being a cognitive neuroscientist may actually be useful </p> </div> <p>The answer was revealed to be (C) - Get a joke. <b>But is this the right answer? Or is this another case of a flawed question?</b></p> <p><b>There are actually several problems with this question.</b> The first is it‚Äôs ambiguity. To say that there is a single correct answer and three incorrect answers suggests that the other three actions do not activate the vmPFC. But that isn‚Äôt true. The vmPFC (as with all other brain areas) is active during all four processes. In fact, it‚Äôs active during any cognitive process! It‚Äôs too naive to state that parts of the brain are discretely ‚Äòon‚Äô and ‚Äòoff‚Äô, and too vague to state that they ‚Äòactivate‚Äô and ‚Äòdeactivate‚Äô in response to a stimulus. Instead, one can say that regions of the brain increase and decrease in their magnitude of activity relative to some baseline condition (i.e., when doing nothing) which happens - to varying degrees - for a particular cognitive process. <b>Ultimately, in cognitive neuroscience, we are interested in determining exactly that, the statistical significance of changes in activity measured across two or more experimental conditions.</b></p> <p>As a simple case, one could define two conditions: getting a joke (condition A) vs. listening to a joke but not getting it (condition B). Instead of asking ‚ÄúIs region X active?‚Äù (which is a moot questions as it always is), the question to ask is whether region X is more active during condition A than condition B. This is statistically tested using a contrast analysis between the two conditions.</p> <div style="text-align: center;"> <img src="/assets/img/posts/millionaire/fmri_contrast.jpg" alt="fmri contrast" width="600"/> <p style="margin-top: 10px; color: #555; font-size: 20px; text-align: center;"> fMRI (and neuroimaging in general) often relies upon measuring the relative change in brain activity between two (or more) conditions </p> </div> <p>So, the formatting of the question automatically renders the question moot, with all four answers technically being correct. A better phrasing of the question would perhaps be:</p> <p><b>‚ÄúWhich of these cognitive processes is most typically associated with activity of the ventromedial prefrontal cortex?‚Äù</b></p> <p>But again, there are flaws with this formulation of the question as well. If stating that a cognitive process is ‚Äòmore typically‚Äô associated with a particular brain region, how can that be determined? You could do a meta-analysis (i.e. a study of studies) of the relevant neuroimaging literature to see which has a more robust association, but I will assume that such a meta-analysis was not consulted by the producers back in February 2004!</p> <p>More worryingly, a quick search of the literature (which admittedly the majority of studies were published after 2004) will in fact show that the <b>vmPFC is strongly implicated with memory,</b> with vmPFC damage robustly affecting autobiographical memory recall (Bertossi et al., 2016; McCormick et al., 2018). <b>By association, the vmPFC is also activated when listening to music if it triggers an autobiographical memory!</b> (Janata, 2009) Functional magnetic resonance imaging (fMRI) studies further show that listening to popular familiar songs (Ford et al., 2016), as well as unfamiliar classical music (Trost et al., 2012) both lead to increased vmPFC activity, stemming from positive emotions such as nostalgia and tenderness (Hennessy et al., 2025; Trost et al., 2012).</p> <p>Understanding whether the vmPFC is also active when having a panic attack is a bit trickier. Whilst the role of the prefrontal cortex more generally in panic disorder is well known, due to its involvement as part of the ‚Äòfear network‚Äô (Gorman et al., 2013) since the question distinctly mentions the process of having a panic attack, we will exclude typical study designs which would compare brain activity at rest between two patient groups (i.e., neurotypicals with panic disorder and healthy controls) or by inducing emotions representative of a panic attack (i.e., fear, anxiety). But, to run a study where participants are induced into a panic attack is ethically questionable!</p> <p>However, we can draw on a few studies where this happened unexpectedly during the course of an experiment. In one case, two anxiety disorder patients spontaneously experienced a panic attack whilst undergoing fMRI scans. These patients demonstrated changes in activity of the dorsolateral prefrontal cortex (dlPFC) specifically when the panic attack occurred (Dresler et al., 2011). Similar instances also strongly implicate other regions of the ‚Äòfear network‚Äô including amygdala and insular cortex (Fischer et al., 1998; Pfleiderer et al., 2007; Spiegelhalder et al., 2009). So, whilst the prefrontal cortex is certainly involved in the fear response, <b>we currently lack direct evidence that the vmPFC specifically changes in activity during a panic attack.</b></p> <div style="text-align: center;"> <img src="/assets/img/posts/millionaire/vmpfc.jpg" alt="vmPFC" width="600"/> <p style="margin-top: 10px; color: #555; font-size: 20px; text-align: center;"> Areas of the prefrontal cortex - including vmPFC </p> </div> <p><b>So, we can state that some of the ‚Äòincorrect‚Äô answers are actually correct.</b> But is the ‚Äòcorrect‚Äô answer correct? Is the vmPFC indeed activated when we ‚Äòget a joke‚Äô? Evidence actually suggests that it is humour appreciation (i.e., the amusement with getting a joke) and not humour comprehension which is precisely related to vmPFC activity (Adamczyk et al., 2019; Chan, 2024). Conversely, evidence suggests that the midbrain and amygdala are more strongly associated with the actual element of ‚Äògetting a joke‚Äô (Chan et al., 2016, 2018; Nakamura et al., 2018). So, it turns out that not only were the wrong answers correct, but the right answer was incorrect!</p> <p><b>Ultimately, the scientifically informed answer to Todd‚Äôs question would be either (B) or (D), not (A).</b></p> <p>What can we take away from all of this? Todd will most likely not be invited back to complete his game 21 years later. Having had a successful career in law, recently as the United States Assistant Attorney General for the Environment and Natural Resources Division under the Biden Administration, and the first solicitor general of the District of Columbia for more than a decade before that, I doubt that he would need the money. But we can learn that <b>claims in science, - particularly cognitive neuroscience - need to be specific and precise. It is far too simplistic to state that parts of the brain are ‚Äòactivated‚Äô and ‚Äòdeactivated‚Äô, and are involved in one function but not another.</b> That‚Äôs not to say that the brain should be excluded from trivia questions - far from it in fact<sup>3</sup> - but they need to be held to more scrutiny than most.</p> <h2 id="references">References</h2> <p>Adamczyk, P., Wyczesany, M., &amp; Daren, A. (2019). Dynamics of impaired humour processing in schizophrenia‚ÄìAn EEG effective connectivity study. Schizophrenia Research, 209, 113-128.</p> <p>Bertossi, E., Tesini, C., Cappelli, A., &amp; Ciaramelli, E. (2016). Ventromedial prefrontal damage causes a pervasive impairment of episodic memory and future thinking. Neuropsychologia, 90, 12-24.</p> <p>Chan, Y. C. (2016). Neural correlates of deficits in humor appreciation in gelotophobics. Scientific Reports, 6(1), 34580.</p> <p>Chan, Y. C., Hsu, W. C., Liao, Y. J., Chen, H. C., Tu, C. H., &amp; Wu, C. L. (2018). Appreciation of different styles of humor: An fMRI study. Scientific reports, 8(1), 15649.</p> <p>Chan, Y. C. (2024). 4 The Neuroscience of Humor. De Gruyter Handbook of Humor Studies, 2, 65.</p> <p>Dresler, T., Hahn, T., Plichta, M. M., Ernst, L. H., Tupak, S. V., Ehlis, A. C., ‚Ä¶ &amp; Fallgatter, A. J. (2011). Neural correlates of spontaneous panic attacks. Journal of neural transmission, 118, 263-269.</p> <p>Gorman, J. M., Kent, J. M., Sullivan, G. M., &amp; Coplan, J. D. (2013). Neuroanatomical hypothesis of panic disorder, revised (pp. 245-257). Routledge.</p> <p>Fischer, H., Andersson, J. L., Furmark, T., &amp; Fredrikson, M. (1998). Brain correlates of an unexpected panic attack: a human positron emission tomographic study. Neuroscience letters, 251(2), 137-140.</p> <p>Ford, J. H., Rubin, D. C., &amp; Giovanello, K. S. (2016). The effects of song familiarity and age on phenomenological characteristics and neural recruitment during autobiographical memory retrieval. Psychomusicology: Music, Mind, and Brain, 26(3), 199.</p> <p>Hennessy, S., Janata, P., Ginsberg, T., Kaplan, J., &amp; Habibi, A. (2025). Music‚ÄêEvoked Nostalgia Activates Default Mode and Reward Networks Across the Lifespan. Human brain mapping, 46(4), e70181.</p> <p>Janata, P. (2009). The neural architecture of music-evoked autobiographical memories. Cerebral Cortex, 19(11), 2579-2594.</p> <p>McCormick, C., Ciaramelli, E., De Luca, F., &amp; Maguire, E. A. (2018). Comparing and contrasting the cognitive effects of hippocampal and ventromedial prefrontal cortex damage: a review of human lesion studies. Neuroscience, 374, 295-318.</p> <p>Nakamura, T., Matsui, T., Utsumi, A., Yamazaki, M., Makita, K., Harada, T., ‚Ä¶ &amp; Sadato, N. (2018). The role of the amygdala in incongruity resolution: The case of humor comprehension. Social neuroscience, 13(5), 553-565.</p> <p>Pfleiderer, B., Zinkirciran, S., Arolt, V., Heindel, W., Deckert, J., &amp; Domschke, K. (2007). fMRI amygdala activation during a spontaneous panic attack in a patient with panic disorder. The World Journal of Biological Psychiatry, 8(4), 269-272.</p> <p>Spiegelhalder, K., Hornyak, M., Kyle, S. D., Paul, D., Blechert, J., Seifritz, E., ‚Ä¶ &amp; Feige, B. (2009). Cerebral correlates of heart rate variations during a spontaneous panic attack in the fMRI scanner. Neurocase, 15(6), 527-534.</p> <p>Trost, W., Ethofer, T., Zentner, M., &amp; Vuilleumier, P. (2012). Mapping aesthetic musical emotions in the brain. Cerebral cortex, 22(12), 2769-2783.</p> <h3 id="footnotes">Footnotes</h3> <p><sup>1</sup> - In the conventional format</p> <p><sup>2</sup> - Counting Ike and Alan Barinholtz‚Äô win in August 2024 as a single case</p> <p><sup>3</sup> - Recently on an episode of UK Millionaire aired 11 May 2025, contestant Mike Hayes was asked for ¬£250,000:</p> <p><b>‚ÄúWhich part of the human brain, connected to the pituitary gland, is responsible for controlling heart rate and body temperature?‚Äù</b></p> <p>The options were (A) Hypothalamus, (B) Amygdala, (C) Frontal lobe, (D) Hippocampus. He ultimately did not know and walked with ¬£125,000.</p> <h3 id="answers">Answers:</h3> <p><b>(B) ‚Äì Le Duc Tho</b> - Le Duc Tho was awarded the Nobel Peace Prize in 1973 ‚Äúfor jointly having negotiated a cease fire in Vietnam‚Äù but declined as he felt the ceasefire conditions were violated by the US.</p> <p><b>(C) ‚Äì Stendhal‚Äôs syndrome</b> ‚Äì Writing under the pseudonym of ‚ÄúStendhal‚Äù, Marie-Henri Beyle first described a profound reaction to art whilst traveling the early 19th century.</p> <p><b>(A) ‚Äì Igor Sikorsky</b> ‚Äì Sikorsky worked on his first helicopters in the 1930s and 40‚Äôs.</p> <p><b>(C) ‚Äì Insecticide</b> ‚Äì Designed by USDA researchers Lyle Goodhue and William Sullivan, the first mass produced aerosol cans contained insecticide and were used by soldiers in the Pacific theatre during WW2.</p> <p><b>(A) ‚Äì Machus Red Fox</b> ‚Äì Hoffa had scheduled for a meeting at the restaurant and was kidnapped after neither of the attendees turned up.</p> <p><b>(D) ‚Äì Herman‚Äôs Head</b> ‚Äì On November 17, 1991, FOX became the first national broadcast television network to run a condom commercial, a 15-second spot for its Trojan Extra Strength brand.</p> <p><b>(A) ‚Äì Hypothalamus</b> ‚Äì The hypothalamus is the part of the brain involved with regulating many important bodily functions including body temperature, hunger, fatigue, sleep and social behaviours.</p> <h3 id="credits">Credits</h3> <p>Photos taken from the Millionaire Wiki and National Institute of Mental Health (NIMH). Functional MRI image by Lea Alhilali (https://radiopaedia.org/courses/neuroradiology-threads-by-lea-alhilali/pages/1848). Content is available under CC-BY-SA.</p>]]></content><author><name></name></author><category term="article"/><category term="millionaire,"/><category term="gameshows,"/><category term="prefrontal"/><category term="cortex"/><summary type="html"><![CDATA[And the forgotten flawed million-dollar question]]></summary></entry><entry><title type="html">Creating reproducible environments using pip, renv, Docker and Code Ocean</title><link href="https://sohaamir.github.io/blog/2025/reproducibility_tools-copy/" rel="alternate" type="text/html" title="Creating reproducible environments using pip, renv, Docker and Code Ocean"/><published>2025-02-08T15:35:00+00:00</published><updated>2025-02-08T15:35:00+00:00</updated><id>https://sohaamir.github.io/blog/2025/reproducibility_tools%20copy</id><content type="html" xml:base="https://sohaamir.github.io/blog/2025/reproducibility_tools-copy/"><![CDATA[<p>In modern research practice, it is commonplace to share code and data freely. Doing so allows others to examine and test their own scientific theories without incurring the time and monetary costs of collecting data (which is particularly useful for larger datasets). <b>Importantly, sharing code and data also allows for the results to be interrogated more thoroughly and accurately.</b> If researcher X reports a particular finding, then researcher Y can test whether this finding is true by re-producing the analysis themselves. In doing so, others can also test alternative analyses or statistical techniques on the same research question.</p> <p>To share code and data openly to this end requires an <b>element of reproducibility - a means by which an identical environment to the original researcher can be recreated.</b> However, this is not as straightforward as it may initially seem, as reprodcibility spans several elements. Firstly, one must consider the software and macro-scale components of research. Programming languages such as Stan, <code class="language-plaintext highlighter-rouge">R</code> and Python are constantly being updated, as are software like RStudio. Different versions of software can ultimately impede reproducibility.</p> <h2 id="managing-package-versions-in-python-using-pip">Managing package versions in Python using <code class="language-plaintext highlighter-rouge">pip</code></h2> <p>Also constantly updating, are the specific packages and tools used within these environments. Bugs need to be fixed, improvements made and features added. Given the constantly evolving state of packages and software, you can see how versioning is a particularly useful feature of any research project.</p> <p>There exist several useful features and tools for version controlling your software packages. For predominantly Python-based projects, a virtual environment <code class="language-plaintext highlighter-rouge">venv</code> is commonly used.</p> <p>You can create a new virtual environment by running:</p> <p><code class="language-plaintext highlighter-rouge">python -m venv myenv</code></p> <p>And then activating that environment (on Mac) by running:</p> <p><code class="language-plaintext highlighter-rouge">source myenv/bin/activate</code></p> <p>You can then install packages using the <code class="language-plaintext highlighter-rouge">pip</code> command:</p> <p><code class="language-plaintext highlighter-rouge">pip install pandas numpy</code></p> <p>And save the list of installed packages to a <code class="language-plaintext highlighter-rouge">requirements.txt</code> file:</p> <p><code class="language-plaintext highlighter-rouge">pip freeze &gt; requirements.txt</code></p> <p><b>This is particularly important - and is where the idea of reproducibility arrives -</b> as others can install the list of Python packages used by someone else by running a simple command:</p> <p><code class="language-plaintext highlighter-rouge">pip install -r requirements.txt</code></p> <p>Which will install the python packages listed e.g.,</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ipykernel&gt;<span class="o">=</span>6.0.0
jupyter&gt;<span class="o">=</span>1.0.0
jupyter-client&gt;<span class="o">=</span>7.0.0
nbformat&gt;<span class="o">=</span>5.0.0
notebook&gt;<span class="o">=</span>6.0.0
nbconvert&gt;<span class="o">=</span>6.0.0
</code></pre></div></div> <blockquote> <p>Within this file, you can specify a certain version (as I have done above); leaving it blank will install the latest.</p> </blockquote> <p>Another somewhat relevant and useful command is one which lists both the current version of a package installed on your environment, as well as the version history of that package more generally.</p> <p>To do this, run the command:</p> <p><code class="language-plaintext highlighter-rouge">pip index versions &lt;package&gt;</code></p> <p>For example, typing:</p> <p><code class="language-plaintext highlighter-rouge">pip index versions numpy</code></p> <p>gives the following output:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>‚ùØ pip index versions numpy
WARNING: pip index is currently an experimental command. It may be removed/changed <span class="k">in </span>a future release without prior warning.
numpy <span class="o">(</span>2.2.2<span class="o">)</span>
Available versions: 2.2.2, 2.2.1, 2.2.0, 2.1.3, 2.1.2, 2.1.1, 2.1.0, 2.0.2, 2.0.1, 2.0.0, 1.26.4, 1.26.3, 1.26.2, 1.26.1, 1.26.0, 1.25.2, 1.25.1, 1.25.0, 1.24.4, 1.24.3, 1.24.2, 1.24.1, 1.24.0, 1.23.5, 1.23.4, 1.23.3, 1.23.2, 1.23.1, 1.23.0, 1.22.4, 1.22.3, 1.22.2, 1.22.1, 1.22.0, 1.21.1, 1.21.0, 1.20.3, 1.20.2, 1.20.1, 1.20.0, 1.19.5, 1.19.4, 1.19.3, 1.19.2, 1.19.1, 1.19.0, 1.18.5, 1.18.4, 1.18.3, 1.18.2, 1.18.1, 1.18.0, 1.17.5, 1.17.4, 1.17.3, 1.17.2, 1.17.1, 1.17.0, 1.16.6, 1.16.5, 1.16.4, 1.16.3, 1.16.2, 1.16.1, 1.16.0, 1.15.4, 1.15.3, 1.15.2, 1.15.1, 1.15.0, 1.14.6, 1.14.5, 1.14.4, 1.14.3, 1.14.2, 1.14.1, 1.14.0, 1.13.3, 1.13.1, 1.13.0, 1.12.1, 1.12.0, 1.11.3, 1.11.2, 1.11.1, 1.11.0, 1.10.4, 1.10.2, 1.10.1, 1.10.0.post2, 1.9.3, 1.9.2, 1.9.1, 1.9.0, 1.8.2, 1.8.1, 1.8.0, 1.7.2, 1.7.1, 1.7.0, 1.6.2, 1.6.1, 1.6.0, 1.5.1, 1.5.0, 1.4.1, 1.3.0
  INSTALLED: 1.26.4
  LATEST:    2.2.2
</code></pre></div></div> <p>Which lets us know that the version of <code class="language-plaintext highlighter-rouge">numpy</code> currently installed in the environment (1.26.4) is not the same as the latest (2.2.2). You can also see that this is the case by typing <code class="language-plaintext highlighter-rouge">pip list</code> which lists all python packages in the current environment:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
nltk                                     3.8.1
numpy                                    1.26.4
oauthlib                                 3.2.2
...
</code></pre></div></div> <blockquote> <p><strong>Tip:</strong> While a <code class="language-plaintext highlighter-rouge">virtualenv</code> works well for Python-only projects, using a <code class="language-plaintext highlighter-rouge">conda</code> environment is more appropriate when working with multiple programming languages (like R) or system libraries.</p> </blockquote> <h2 id="reproducibility-within-rrstudio-projects">Reproducibility within R/RStudio projects</h2> <p>RStudio is very popular software used for statistical analysis. Similarly to Python, reproducibility - and issues therein - with RStudio environments exist at multiple levels. We will discuss two approaches to reproducibility in RStudio: <a href="https://rstudio.github.io/renv/articles/renv.html"><code class="language-plaintext highlighter-rouge">renv</code></a> for package versioning and using <a href="https://docker.com">Docker</a> to create a reproducible environment. We will then introduce <a href="https://codeocean.com/">Code Ocean</a>, an online platform for hosting reproducible environments which make it easier for others to generate and replicate your scientific analyses.</p> <p><br/></p> <h3 id="package-versioning-in-r-using-renv">Package versioning in R using <code class="language-plaintext highlighter-rouge">renv</code></h3> <p>As we have seen above with <code class="language-plaintext highlighter-rouge">pip</code> in Python environments, packages are always being updated and you should always keep track of which versions you are using. Unfortunately there isn‚Äôt a direct equivalent of <code class="language-plaintext highlighter-rouge">pip</code> and virtual environments in R, however <code class="language-plaintext highlighter-rouge">renv</code> follows a similar principle.</p> <p>Similar to virtual environments, <code class="language-plaintext highlighter-rouge">renv</code> provides pacakge management specific to each project, meaning each project maintains its own private package library. However, it tracks and records all package dependencies in a lockfile, creating a detailed ‚Äòsnapshot‚Äô of a project‚Äôs environment that includes specific versions of packages and their dependencies. It can handle packages from CRAN, GitHub, Bioconductor, and local sources, making it versatile for projects that require packages from various locations.</p> <p>When using <code class="language-plaintext highlighter-rouge">renv</code>, after installing it, you need to firstly initialize it for the current project:</p> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">renv</span><span class="o">::</span><span class="n">init</span><span class="p">()</span><span class="w">
</span></code></pre></div></div> <p>This subsequently creates:</p> <ul> <li><code class="language-plaintext highlighter-rouge">renv.lock</code>: A specific file whcih records package versions</li> <li><code class="language-plaintext highlighter-rouge">renv/</code>: A directory containing the project library</li> <li><code class="language-plaintext highlighter-rouge">.Rprofile</code>: A project-specific R profile</li> </ul> <p>The <code class="language-plaintext highlighter-rouge">renv.lock</code> file may look something like this:</p> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="s2">"R"</span><span class="o">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="s2">"Version"</span><span class="o">:</span><span class="w"> </span><span class="s2">"4.1.2"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Repositories"</span><span class="o">:</span><span class="w"> </span><span class="p">[</span><span class="w">
      </span><span class="p">{</span><span class="w">
        </span><span class="s2">"Name"</span><span class="o">:</span><span class="w"> </span><span class="s2">"CRAN"</span><span class="p">,</span><span class="w">
        </span><span class="s2">"URL"</span><span class="o">:</span><span class="w"> </span><span class="s2">"https://cloud.r-project.org"</span><span class="w">
      </span><span class="p">}</span><span class="w">
    </span><span class="p">]</span><span class="w">
  </span><span class="p">},</span><span class="w">
  </span><span class="s2">"Packages"</span><span class="o">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="s2">"dplyr"</span><span class="o">:</span><span class="w"> </span><span class="p">{</span><span class="w">
      </span><span class="s2">"Package"</span><span class="o">:</span><span class="w"> </span><span class="s2">"dplyr"</span><span class="p">,</span><span class="w">
      </span><span class="s2">"Version"</span><span class="o">:</span><span class="w"> </span><span class="s2">"1.0.7"</span><span class="p">,</span><span class="w">
      </span><span class="s2">"Source"</span><span class="o">:</span><span class="w"> </span><span class="s2">"Repository"</span><span class="p">,</span><span class="w">
      </span><span class="s2">"Repository"</span><span class="o">:</span><span class="w"> </span><span class="s2">"CRAN"</span><span class="w">
    </span><span class="p">},</span><span class="w">
    </span><span class="s2">"ggplot2"</span><span class="o">:</span><span class="w"> </span><span class="p">{</span><span class="w">
      </span><span class="s2">"Package"</span><span class="o">:</span><span class="w"> </span><span class="s2">"ggplot2"</span><span class="p">,</span><span class="w">
      </span><span class="s2">"Version"</span><span class="o">:</span><span class="w"> </span><span class="s2">"3.3.5"</span><span class="p">,</span><span class="w">
      </span><span class="s2">"Source"</span><span class="o">:</span><span class="w"> </span><span class="s2">"Repository"</span><span class="p">,</span><span class="w">
      </span><span class="s2">"Repository"</span><span class="o">:</span><span class="w"> </span><span class="s2">"CRAN"</span><span class="w">
    </span><span class="p">}</span><span class="w">
  </span><span class="p">}</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div> <p>listing the version of R itself, as well as the packages installed within that project.</p> <p>You can install packages both normally, or by using the <code class="language-plaintext highlighter-rouge">renv::install</code> function, but in either case, you need to update your lock file to be up to date.</p> <p>There are three primary commands when using <code class="language-plaintext highlighter-rouge">renv</code> - <code class="language-plaintext highlighter-rouge">snapshot()</code>, <code class="language-plaintext highlighter-rouge">restore()</code>, and <code class="language-plaintext highlighter-rouge">status()</code> - each of which serve distinct but interconnected purposes in managing R project environments.</p> <ul> <li> <p>The <code class="language-plaintext highlighter-rouge">snapshot()</code> command is responsible for capturing the complete state of your project‚Äôs package environment - as the name suggests, think of it like taking a picture. This information is then written to the <code class="language-plaintext highlighter-rouge">renv.lock</code> file, and any changes from previous snapshots are automatically updated, ensuring the lockfile remains current with your project‚Äôs needs.</p> </li> <li> <p>The <code class="language-plaintext highlighter-rouge">restore()</code> command functions as the complement to <code class="language-plaintext highlighter-rouge">snapshot()</code>, as it rebuilds your project environment based on the information stored in the lockfile. When ran, <code class="language-plaintext highlighter-rouge">restore()</code> reads the renv.lock file and systematically installs all packages at their specified versions.</p> </li> <li> <p>The <code class="language-plaintext highlighter-rouge">status()</code> command provides a comparison between your current environment and the lockfile, usefully highlighting which packages are out of sync. The command also identifies any missing packages that should be present according to the lockfile, as well as new packages that have been installed but not yet recorded.</p> </li> </ul> <p>For example, after updating some packages - but not updating your lock file - running <code class="language-plaintext highlighter-rouge">renv.status</code> might produce something like this:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt; renv::status()
The following package(s) are out of sync:

  Package  Installed Lockfile
  dplyr    1.0.8     1.0.7   
  ggplot2  3.3.6     3.3.5   

Use `renv::snapshot()` to save changes to lockfile
</code></pre></div></div> <p>After appropriately running <code class="language-plaintext highlighter-rouge">renv.snapshot()</code> and <code class="language-plaintext highlighter-rouge">renv.restore()</code>, this will change to:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>`&gt; renv::status()
No issues found -- the project is in a consistent state.
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">renv</code> also makes it easy for others to install all of the packages listed within a specific project. For example, if hosting a repository on GitHub, one can simply download the repository, and - after opening the project - need to only run two simple commands:</p> <ol> <li> <p>Install <code class="language-plaintext highlighter-rouge">renv</code> - <code class="language-plaintext highlighter-rouge">install.packages("renv")</code></p> </li> <li> <p>Restore the environment - <code class="language-plaintext highlighter-rouge">renv::restore()</code></p> </li> </ol> <p>This can be made even simpler by creating a <code class="language-plaintext highlighter-rouge">setup.R</code> file within the project root with:</p> <div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="o">!</span><span class="n">require</span><span class="p">(</span><span class="s2">"renv"</span><span class="p">))</span><span class="w"> </span><span class="n">install.packages</span><span class="p">(</span><span class="s2">"renv"</span><span class="p">)</span><span class="w">
</span><span class="n">renv</span><span class="o">::</span><span class="n">restore</span><span class="p">()</span><span class="w">
</span></code></pre></div></div> <p>Then all you need to do is run:</p> <p><code class="language-plaintext highlighter-rouge">source("setup.R")</code></p> <p><br/></p> <h3 id="containerizing-environments-using-docker">Containerizing environments using Docker</h3> <p>We can see that <code class="language-plaintext highlighter-rouge">renv</code> is particularly useful at managing R package dependencies within a project, ensuring that specific versions of packages are tracked and can be reproduced. However, <code class="language-plaintext highlighter-rouge">renv</code> has several limitations.</p> <p>Beyond <code class="language-plaintext highlighter-rouge">R</code> packages, it cannot manage system-level dependencies, different versions of <code class="language-plaintext highlighter-rouge">R</code> itself, or dependencies outside the R ecosystem. For instance, if your project requires specific system libraries or external software, <code class="language-plaintext highlighter-rouge">renv</code> isn‚Äôt much use. Recall that different people may have different versions of Python - the same can be said for <code class="language-plaintext highlighter-rouge">R</code> and RStudio:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>R.version

               _                           
platform       x86_64-apple-darwin20       
arch           x86_64                      
os             darwin20                    
system         x86_64, darwin20            
status                                     
major          4                           
minor          4.1                         
year           2024                        
month          06                          
day            14                          
svn rev        86737                       
language       R                           
version.string R version 4.4.1 (2024-06-14)
nickname       Race for Your Life     

</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>RStudio.version()

$version
[1] ‚Äò2024.12.0.467‚Äô

$long_version
[1] "2024.12.0+467"

$release_name
[1] "Kousa Dogwood"
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">renv</code> also doesn‚Äôt address differences in operating systems or hardware configurations.</p> <p>This is where <a href="https://www.docker.com/">Docker</a> comes in. While <code class="language-plaintext highlighter-rouge">renv</code> operates at the package level, <b>Docker operates at the system level, creating completely isolated environments that include everything needed to run an application - from the operating system, software and packages.</b> Relevant to R ecosystems, Docker can package not just R and its packages, but also system libraries, external software, and even specific operating system configurations.</p> <p><b>Docker involves two core concepts: images and containers.</b> Docker images serve as templates that contain all the necessary components for running an application. Similar to how <code class="language-plaintext highlighter-rouge">renv</code> took a snapshot of the packages within R, a Docker image does the same but on a wider scale - doing so for a complete system, including the operating system, installed software, libraries, and configurations.</p> <p>Docker containers are the running instances created from these images. When you start a container, Docker takes the image and adds a writable layer on top, allowing the container to modify files while keeping the underlying image unchanged. Each container runs in its own namespace with its own filesystem, network interface, and process space, ensuring that applications run consistently regardless of the host environment.</p> <p>Let‚Äôs see the relationship between images and containers though an example. We will use the case for an online course that I helped to develop, <a href="https://sohaamir.github.io/BayesCog/">BayesCog</a>, which uses Docker containers to create a reproducible RStudio environment.</p> <p>We firstly create the Docker image using a Dockerfile, the ‚Äòrecipe‚Äô for the image where we list all of our requires software and packages. A minimalistic Dockerfile for the BayesCog repository is:</p> <div class="language-Dockerfile highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Use specific R version</span>
<span class="k">FROM</span><span class="s"> rocker/rstudio:4.4.1</span>

<span class="c"># Install system dependencies (these are needed for some R packages)</span>
<span class="k">RUN </span>apt-get update <span class="o">&amp;&amp;</span> apt-get <span class="nb">install</span> <span class="nt">-y</span> <span class="se">\
</span>    libxml2-dev <span class="se">\
</span>    libcairo2-dev <span class="se">\
</span>    libgit2-dev <span class="se">\
</span>    libglpk40 <span class="se">\
</span>    libglu1-mesa-dev <span class="se">\
</span>    libgmp3-dev <span class="se">\
</span>    libgsl0-dev <span class="se">\
</span>    libssl-dev <span class="se">\
</span>    <span class="o">&amp;&amp;</span> apt-get clean <span class="se">\
</span>    <span class="o">&amp;&amp;</span> <span class="nb">rm</span> <span class="nt">-rf</span> /var/lib/apt/lists/<span class="k">*</span>

<span class="c"># Install R packages with specific versions (the same as in the renv.lock file)</span>
<span class="k">RUN </span>R <span class="nt">-e</span> <span class="s2">"install.packages(c(</span><span class="se">\
</span><span class="s2">    'renv=1.0.11', </span><span class="se">\
</span><span class="s2">    'ggplot2=3.5.1', </span><span class="se">\
</span><span class="s2">    'lattice=0.22-6', </span><span class="se">\
</span><span class="s2">    'rmarkdown=2.29', </span><span class="se">\
</span><span class="s2">    'patchwork=1.3.0', </span><span class="se">\
</span><span class="s2">    'rstan=2.32.6', </span><span class="se">\
</span><span class="s2">    'reshape2=1.4.4', </span><span class="se">\
</span><span class="s2">    'R.matlab=3.7.0', </span><span class="se">\
</span><span class="s2">    'loo=2.8.0', </span><span class="se">\
</span><span class="s2">    'corrr=0.4.4' </span><span class="se">\
</span><span class="s2">    ), repos='https://cloud.r-project.org/')"</span>

<span class="k">WORKDIR</span><span class="s"> /home/rstudio</span>

<span class="k">CMD</span><span class="s"> ["/init"]</span>
</code></pre></div></div> <p>Without going too much into the details, we can break this file down into specific sections:</p> <ul> <li>The first command, <code class="language-plaintext highlighter-rouge">FROM rocker/rstudio:4.4.1</code>, specifies the base image to use, which in this case is RStudio with the specific <code class="language-plaintext highlighter-rouge">R version 4.4.1</code></li> <li>The second block uses <code class="language-plaintext highlighter-rouge">RUN apt-get</code> to install system-level dependencies that are required by various R packages. These are Linux libraries that certain R packages need to function properly.</li> <li>The third block uses <code class="language-plaintext highlighter-rouge">RUN R -e</code> to install specific R packages with exact versions.</li> <li><code class="language-plaintext highlighter-rouge">WORKDIR /home/rstudio</code> sets the working directory.</li> <li>The final line CMD [‚Äú/init‚Äù] specifies the command that should run when the container starts, which in this case launches the RStudio server</li> </ul> <p>There are a few notes about this specific Dockerfile, which combat some of the technical components of reproducibility.</p> <p><b>Firstly, we specify the creation of an RStudio server</b> that users can interact with, separate to their own RStudio, which may be different. You don‚Äôt need to do this, but it helps maintain consistency and is useful for those without RStudio installed locally.</p> <p>We also - in this version of the Dockerfile - <b>provide specific versions for both RStudio and the R packages themselves.</b> This has both pros and cons; whilst it increases reproducibility ensuring that the specific packages used to run an analysis are installed, it also means that the packages may become out of date in the future, with bugs and patches not being updated. It is therefore a good idea to give people the flexibility to either install the specific versions used to create the original analysis, or to install the latest versions:</p> <div class="language-Dockerfile highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Use specific R version</span>
<span class="k">FROM</span><span class="s"> rocker/rstudio:4.4.1</span>

<span class="c"># To use latest version instead, use:</span>
<span class="c"># FROM rocker/rstudio:latest</span>

<span class="c"># Install system dependencies (these are needed for some R packages)</span>
<span class="k">RUN </span>apt-get update <span class="o">&amp;&amp;</span> apt-get <span class="nb">install</span> <span class="nt">-y</span> <span class="se">\
</span>    libxml2-dev <span class="se">\
</span>    libcairo2-dev <span class="se">\
</span>    libgit2-dev <span class="se">\
</span>    libglpk40 <span class="se">\
</span>    libglu1-mesa-dev <span class="se">\
</span>    libgmp3-dev <span class="se">\
</span>    libgsl0-dev <span class="se">\
</span>    libssl-dev <span class="se">\
</span>    <span class="o">&amp;&amp;</span> apt-get clean <span class="se">\
</span>    <span class="o">&amp;&amp;</span> <span class="nb">rm</span> <span class="nt">-rf</span> /var/lib/apt/lists/<span class="k">*</span>

<span class="c"># Install R packages with specific versions (the same as in the renv.lock file)</span>
<span class="k">RUN </span>R <span class="nt">-e</span> <span class="s2">"install.packages(c(</span><span class="se">\
</span><span class="s2">    'renv=1.0.11', </span><span class="se">\
</span><span class="s2">    'ggplot2=3.5.1', </span><span class="se">\
</span><span class="s2">    'lattice=0.22-6', </span><span class="se">\
</span><span class="s2">    'rmarkdown=2.29', </span><span class="se">\
</span><span class="s2">    'patchwork=1.3.0', </span><span class="se">\
</span><span class="s2">    'rstan=2.32.6', </span><span class="se">\
</span><span class="s2">    'reshape2=1.4.4', </span><span class="se">\
</span><span class="s2">    'R.matlab=3.7.0', </span><span class="se">\
</span><span class="s2">    'loo=2.8.0', </span><span class="se">\
</span><span class="s2">    'corrr=0.4.4' </span><span class="se">\
</span><span class="s2">    ), repos='https://cloud.r-project.org/')"</span>

<span class="c"># To use latest package versions instead, remove the version numbers:</span>
<span class="c"># RUN R -e "install.packages(c(\</span>
<span class="c">#     'renv', \</span>
<span class="c">#     'ggplot2', \</span>
<span class="c">#     'lattice', \</span>
<span class="c">#     'rmarkdown', \</span>
<span class="c">#     'patchwork', \</span>
<span class="c">#     'rstan', \</span>
<span class="c">#     'reshape2', \</span>
<span class="c">#     'R.matlab', \</span>
<span class="c">#     'loo', \</span>
<span class="c">#     'corrr' \</span>
<span class="c">#     ), repos='https://cloud.r-project.org/')"</span>

<span class="k">WORKDIR</span><span class="s"> /home/rstudio</span>

<span class="k">CMD</span><span class="s"> ["/init"]</span>
</code></pre></div></div> <p>Docker makes it easy to build, upload, share and download images. For example, with the Dockerfile for the BayesCog repository, to create and upload the Dockerfile as a Docker image, you need to do the following:</p> <p>(assuming here that I call the image <code class="language-plaintext highlighter-rouge">bayescog</code> and am using my Docker account called <code class="language-plaintext highlighter-rouge">sohamir</code>)</p> <p>First build the image locally:</p> <p><code class="language-plaintext highlighter-rouge">docker build -t bayescog .</code></p> <p>Then tag the image with your Docker Hub username:</p> <p><code class="language-plaintext highlighter-rouge">docker tag bayescog sohamir/bayescog</code></p> <p>Login to Docker Hub (an online hub for uploading and sharing Docker images) and push the image:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker login <span class="nt">-u</span> sohamir
docker push sohamir/bayescog
</code></pre></div></div> <p>Then, if I am wanting to re-create the environment (either myself or from the perspective of others for reproducibility), in the project root, you can just run:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker pull sohamir/bayescog_test:latest

docker run <span class="nt">-p</span> 8787:8787 <span class="se">\</span>
  <span class="nt">--mount</span> <span class="nb">type</span><span class="o">=</span><span class="nb">bind</span>,source<span class="o">=</span><span class="si">$(</span><span class="nb">pwd</span><span class="si">)</span>,target<span class="o">=</span>/home/rstudio/project <span class="se">\</span>
  <span class="nt">-e</span> <span class="nv">PASSWORD</span><span class="o">=</span>your_chosen_password <span class="se">\</span>
  <span class="nt">--name</span> bayescog_test <span class="se">\</span>
  sohamir/bayescog_test
</code></pre></div></div> <p>This will mount the Docker image onto the BayesCog repository. Then, navigate to <a href="http://localhost:8787/">http://localhost:8787/</a> in a browser, and type your username (which is always <code class="language-plaintext highlighter-rouge">rstudio</code>) and the password chosen in the command prior.</p> <p>Then once RStudio has loaded, click on the project folder; the material will be there and all packages will be installed.</p> <h2 id="sharing-environments-more-easily-using-code-ocean">Sharing environments more easily using Code Ocean</h2> <p>While Docker containers are great for reproducibility, <b>it isn‚Äôt the most accessible of tools</b> - you need to install Docker and be comfortable using the command line. You also have to put in some effort in downloading the image and creating the container. Code Ocean tries to simplfy this process by <b>moving everything to the web browser, making it much easier for researchers to share their work and for others to check their results.</b></p> <p>Think of Code Ocean as a scientific platform that combines the best parts of containers with the simplicity of a website. Researchers can package up their code, data, and computing setup into what Code Ocean calls a ‚Äúcapsule‚Äù - basically everything someone would need to rerun their analysis, all in one place.</p> <p>Using Code Ocean as a researcher is pretty straightforward. When you create a new project, you just tell it what you need:</p> <ul> <li>What programming language you‚Äôre using</li> <li>What packages your code needs</li> <li>Your data and code files</li> <li>How much computing power you need</li> </ul> <p>This is similar to a Dockerfile, but done through a GUI on their website:</p> <div style="text-align: center;"> <img src="/assets/img/posts/reproducibility_tools/code_ocean_specs.png" alt="Code Ocean specs" width="750"/> </div> <p><br/></p> <p>You can use Code Ocean as a cloud-based environment, but <b>it is more appropriate for creating archives of completed analyses.</b> However, to do this, you need to upload your repository details in a specific way:</p> <ol> <li>A main script (<code class="language-plaintext highlighter-rouge">main.py</code>, <code class="language-plaintext highlighter-rouge">run.R</code>, etc.) that will run all of the analyses in your project folder. In other words, this is your primary script that Code Ocean will execute. It must be named appropriately for your language.</li> <li>A code folder <code class="language-plaintext highlighter-rouge">/code</code> containing all your supporting scripts and functions, or helper functions or utilities your main script needs</li> <li>A data folder <code class="language-plaintext highlighter-rouge">/data</code> containing all input data files processed by <code class="language-plaintext highlighter-rouge">/code</code></li> <li>A file to set-up the environment Setup - this can be specified manually (see above) or using the appropriate file in the project directory (e.g., <code class="language-plaintext highlighter-rouge">renv.lock</code>, <code class="language-plaintext highlighter-rouge">requirements.txt</code>)</li> </ol> <p>When you are happy with your requirements and set-up, you can generate a ‚ÄòReproducible Run‚Äô which creates the environment <b>in a read-only capacity. </b></p> <p>Code Ocean then sets everything up in the cloud automatically as Docker would. <b>Anyone can look at your work and rerun your analysis in their web browser, without installing anything on their computer.</b></p> <p>Ultimately, Code Ocean works best as a final snapshot of your completed analyses that others can examine. It does this efficiently and with less hassle than Docker. However, it‚Äôs not really meant to be a platform where people actively work on code. If you‚Äôre teaching a class where students need to write and modify code, or if you‚Äôre actively developing software, you might want to use something else.</p> <p>There‚Äôs a reason why their environments are called ‚Äòcapsules‚Äô!</p> <p>Altogether, you can see how both <code class="language-plaintext highlighter-rouge">renv</code> and Docker can be used with GitHub to help others reproduce your specific working environment:</p> <div style="text-align: center;"> <img src="/assets/img/posts/reproducibility_tools/renv_docker_github.png" alt="Reproducibility workflow" width="750"/> <p style="margin-top: 20px; font-size: 1.2em; color: #666;"> <em>Using Docker and renv together with GitHub can reproduce environments with only a few commands!</em> </p> </div> <p><br/></p>]]></content><author><name></name></author><category term="tutorials"/><category term="reproducibility,"/><category term="Python,"/><category term="pip,"/><category term="Docker,"/><category term="renv,"/><category term="Code"/><category term="Ocean"/><summary type="html"><![CDATA[Understanding the different approaches to computational reproducibility]]></summary></entry><entry><title type="html">Making your course open-source</title><link href="https://sohaamir.github.io/blog/2024/create_mkdocs_website/" rel="alternate" type="text/html" title="Making your course open-source"/><published>2024-11-16T15:35:00+00:00</published><updated>2024-11-16T15:35:00+00:00</updated><id>https://sohaamir.github.io/blog/2024/create_mkdocs_website</id><content type="html" xml:base="https://sohaamir.github.io/blog/2024/create_mkdocs_website/"><![CDATA[<p>University courses are often hosted on a platform such as <a href="https://moodle.org/">Moodle</a>, <a href="https://help.blackboard.com/">Blackboard</a> or <a href="https://www.instructure.com/canvas">Canvas</a>, which restrict access to currently enrolled students. Whilst there is nothing inherently wrong with this approach per se, there are several limitations:</p> <ul> <li>Course materials are not openly available, to the detriment of externals and students on the course in following years</li> <li>The design and strcture of the teaching materials is not ideal for certain courses (e.g., neuroimaging)</li> <li>Updating the materials (e.g., for a new academic year) is laborious and inefficient</li> </ul> <p>Subsequently, many teachers within the field of statistics, psychology and cognitive science now <b>host their course materials on a dedicated webpage.</b> Whilst there are many different approaches, a common one is to place the materials on a GitHub repository, and host the website using GitHub Pages. This has many benefits over the traditional method of hosting course materials:</p> <ul> <li>Version Control - As changes are tracked using <code class="language-plaintext highlighter-rouge">git</code>, contributors can track all changes to materials, easily rollback if needed, and maintain a clear history of updates, making course maintenance straightforward</li> <li>Collaboration - Similarly, <code class="language-plaintext highlighter-rouge">git</code> and GitHub allows for multiple instructors to contribute, and students can suggest fixes through pull requests</li> <li>Accessibility - Materials are freely available online 24/7, with no institutional login needed</li> <li>Cost-effective - Hosting on GitHub Pages is free</li> <li>Open Education - Promotes sharing of resources, allows educators to build upon existing materials, and contributes to open education initiatives</li> </ul> <p><b>So, doing so I think is a no-brainer.</b> Some may think that hosting your own course on GitHub can be daunting, but it‚Äôs actually very simple.</p> <p>Before anything else, your first step is to decide a basic structure and theme. There are many options to choose from, but some of the most popular include <a href="https://jupyterbook.org/en/stable/intro.html">JupyterBook</a> and <a href="https://about.readthedocs.com/">Read the Docs</a>. Some examples of each are listed below:</p> <ul> <li><a href="https://andysbrainbook.readthedocs.io/en/latest/">Andy‚Äôs Brain Book</a></li> <li><a href="https://lukas-snoek.com/NI-edu/index.html">NI-edu</a></li> <li><a href="https://neuroimaging-core-docs.readthedocs.io/en/latest/index.html">U of A: Neuroimaging Core Documentation</a></li> <li><a href="https://schluppeck.github.io/dafni/">Data analysis for Neuroimaging (DAFNI)</a></li> <li><a href="https://bic-berkeley.github.io/psych-214-fall-2016/">Psych 214 ‚Äì functional MRI methods</a></li> <li><a href="https://shawnrhoads.github.io/gu-psyc-347/index.html">Computational Models of Human Social Behavior and Neuroscience</a></li> <li><a href="https://dartbrains.org/content/intro.html">Dartbrains</a></li> </ul> <p><b>This tutorial will specifically cover how to set-up your website using <a href="https://www.mkdocs.org/">MkDocs</a>.</b> I like MkDocs because it‚Äôs very easy to set-up and make changes, and it supports many themes. You can also preview your changes in real time which is very useful!</p> <blockquote> <p>FYI, for this tutorial I will assume that you are working on a Mac‚Ä¶</p> </blockquote> <h2 id="setting-up-the-website-folder-and-github-repository">Setting up the website folder and GitHub repository</h2> <p>Firstly, we should create and set up our website‚Äôs folder locally, install the relevant requirements and connect it to the corresponding GitHub repository.</p> <p>Open up a terminal, and then create and move into the website folder:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">mkdir </span>my-mkdocs-site
<span class="nb">cd </span>my-mkdocs-site
</code></pre></div></div> <p>Then create a virtual environment for the folder:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python <span class="nt">-m</span> venv venv
<span class="nb">source </span>venv/bin/activate
</code></pre></div></div> <p>install the required packages (just the necessary ones to start):</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install </span>mkdocs
pip <span class="nb">install </span>mkdocs-material  <span class="c"># Popular theme, optional but recommended</span>
pip freeze <span class="o">&gt;</span> requirements.txt  <span class="c"># Save dependencies in requirements.txt</span>
</code></pre></div></div> <p>create a <code class="language-plaintext highlighter-rouge">.gitignore</code>:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">touch</span> .gitignore <span class="o">&amp;&amp;</span> <span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"venv/</span><span class="se">\n</span><span class="s2">site/</span><span class="se">\n</span><span class="s2">__pycache__/</span><span class="se">\n</span><span class="s2">.DS_Store"</span> <span class="o">&gt;</span> .gitignore
</code></pre></div></div> <p>and initialize the MkDocs project:</p> <p><code class="language-plaintext highlighter-rouge">mkdocs new .</code></p> <p>Now let‚Äôs create the corresponding repository on GitHub:</p> <ul> <li>Go to your profile on GitHub and create a new repository with the same name (e.g., my-mkdocs-site)</li> <li>But don‚Äôt add anything else e.g., initializing it with a README.md (since you‚Äôll eventually create one locally)</li> </ul> <p>Now let‚Äôs connect the two. Back in your terminal type:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git init
git add <span class="nb">.</span>
git commit <span class="nt">-m</span> <span class="s2">"Initial commit"</span>
git branch <span class="nt">-M</span> main
git remote add origin https://github.com/yourusername/your-repo-name.git
git push <span class="nt">-u</span> origin main
</code></pre></div></div> <p><b>So now our local folder for our website is connected to the GitHub repository.</b></p> <p>You can check this by typing:</p> <p><code class="language-plaintext highlighter-rouge">git remote -v</code></p> <p>which will list the GitHub repository(s) connected:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>‚ùØ git remote <span class="nt">-v</span>
origin	https://github.com/sohaamir/my-mkdocs-site.git <span class="o">(</span>fetch<span class="o">)</span>
origin	https://github.com/sohaamir/my-mkdocs-site.git <span class="o">(</span>push<span class="o">)</span>
</code></pre></div></div> <p>We can now start making some changes to the website‚Äôs content. Open up your code editor of choice. I personally use VS Code, and if you are too, you can open the folder in VS Code directly from the terminal by typing:</p> <p><code class="language-plaintext highlighter-rouge">code .</code></p> <p>In your editor of choice, open up the <code class="language-plaintext highlighter-rouge">mkdocs.yml</code> file. It should just have a single line of code:</p> <p><code class="language-plaintext highlighter-rouge">site_name: My Docs</code></p> <p>Let‚Äôs create a basic structure for our website. Replace that with:</p> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">site_name</span><span class="pi">:</span> <span class="s">Your Site Name</span>
<span class="na">theme</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">material</span>  <span class="c1"># if you installed mkdocs-material</span>
<span class="na">nav</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">Home</span><span class="pi">:</span> <span class="s">index.md</span>
</code></pre></div></div> <p>You can now see your website by running:</p> <p><code class="language-plaintext highlighter-rouge">mkdocs serve</code></p> <p>If you are already running a website on a <code class="language-plaintext highlighter-rouge">localhost</code> (for example when creating this tutorial I also had my personal website running) you will have to specify the port:</p> <p><code class="language-plaintext highlighter-rouge">mkdocs serve -a localhost:XXXX</code></p> <p>In any case, your website should look something like this:</p> <div style="text-align: center;"> <img src="/assets/img/posts/mkdocs-guide/first_mkdocs_deployment.png" alt="First MkDocs" width="750"/> </div> <p><br/></p> <h2 id="hosting-your-site-on-github-pages">Hosting your site on GitHub Pages</h2> <p>At the moment we just have our site running locally (note that in the image above, the web address was <code class="language-plaintext highlighter-rouge">localhost:9999</code>). To actively host it online, we can use GitHub Pages.</p> <blockquote> <p>GitHub Pages is a free hosting service provided by GitHub that takes files from a repository and hosts them as a static website.</p> </blockquote> <p>But to push our changes to the website, we need to set up the associated GitHub Action.</p> <blockquote> <p>GitHub Actions provides automated workflows to build and deploy websites to hosting platforms whenever code changes are pushed to a repository.</p> </blockquote> <p>In other words, GitHub Actions works with GitHub Pages by automatically building your site‚Äôs files and pushing them to a dedicated branch, which <b>GitHub Pages then serves as a live website</b> at <code class="language-plaintext highlighter-rouge">username.github.io/repository-name</code>.</p> <p>First, let‚Äôs create a deployment workflow for our Action. From your project <code class="language-plaintext highlighter-rouge">root</code> on the terminal type:</p> <p><code class="language-plaintext highlighter-rouge">mkdir -p .github/workflows</code></p> <p>and then opening up the file in your editor, replace the contents with:</p> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">name</span><span class="pi">:</span> <span class="s">deploy (only on push to main branch)</span>
<span class="na">on</span><span class="pi">:</span>
  <span class="na">push</span><span class="pi">:</span>
    <span class="na">branches</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s2">"</span><span class="s">main"</span>
<span class="na">jobs</span><span class="pi">:</span>
  <span class="na">build-docs</span><span class="pi">:</span>
    <span class="na">runs-on</span><span class="pi">:</span> <span class="s">ubuntu-latest</span>
    <span class="na">permissions</span><span class="pi">:</span> <span class="s">write-all</span>
    <span class="na">steps</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">checkout</span>
        <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/checkout@v3</span>
        <span class="na">with</span><span class="pi">:</span>
          <span class="na">fetch-depth</span><span class="pi">:</span> <span class="m">0</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">set up Python</span>
        <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/setup-python@v4</span>
        <span class="na">with</span><span class="pi">:</span>
          <span class="na">python-version</span><span class="pi">:</span> <span class="s1">'</span><span class="s">&gt;=3.10'</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">install mkdocs and dependencies</span>
        <span class="na">run</span><span class="pi">:</span> <span class="pi">|</span>
            <span class="s">pip install -r requirements.txt</span>
            <span class="s">mkdocs --version</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">build docs</span>
        <span class="na">run</span><span class="pi">:</span> <span class="s">mkdocs build --strict</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">deploy docs</span>
        <span class="na">run</span><span class="pi">:</span> <span class="s">mkdocs gh-deploy --force</span>
</code></pre></div></div> <p><b>This will re-deploy the website when changes have been commited to the <code class="language-plaintext highlighter-rouge">main</code> branch.</b></p> <p>So now the basic structure of your folder should be:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>my-mkdocs-site/
‚îú‚îÄ‚îÄ .github/
‚îÇ   ‚îî‚îÄ‚îÄ workflows/
‚îÇ       ‚îî‚îÄ‚îÄ deploy.yml
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îî‚îÄ‚îÄ index.md
‚îú‚îÄ‚îÄ venv/
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ mkdocs.yml
‚îî‚îÄ‚îÄ requirements.txt
</code></pre></div></div> <p>Let‚Äôs then commit our basic set-up to GitHub:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git add <span class="nb">.</span>
git commit <span class="nt">-m</span> <span class="s2">"initial commit of basic website"</span>
git push origin main
</code></pre></div></div> <p><b>The website will not be built this time round, so don‚Äôt worry if an error happens.</b></p> <p>We need to now specifically set-up our repository on GitHub to publish the contents to our GitHub site through GitHub Pages.</p> <p>To do this do the following:</p> <ol> <li>Go to your repository on GitHub</li> <li>Go to Settings ‚Üí Pages</li> <li>Set source to ‚ÄúDeploy from a branch‚Äù</li> <li>Select <code class="language-plaintext highlighter-rouge">gh-pages</code> branch and <code class="language-plaintext highlighter-rouge">/ (root)</code></li> </ol> <div style="text-align: center;"> <img src="/assets/img/posts/mkdocs-guide/gh-pages.png" alt="GH Pages" width="750"/> </div> <p><br/></p> <p>Then make any change locally and re-commit:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git add <span class="nb">.</span>
git commit <span class="nt">-m</span> <span class="s2">"testing commit"</span>
git push origin main
</code></pre></div></div> <blockquote> <p>If you didn‚Äôt see the <code class="language-plaintext highlighter-rouge">gh-pages</code> option, and only <code class="language-plaintext highlighter-rouge">main</code> after the initial commit, then select <code class="language-plaintext highlighter-rouge">main</code> and make a second commit. You should then see the <code class="language-plaintext highlighter-rouge">gh-pages</code> option the second time round.</p> </blockquote> <p>Your website should now be deployed! You can go to your newly found website on GitHub by:</p> <ol> <li>Going to ‚ÄòActions‚Äô and selecting the most recent ‚Äòpages build and deployment‚Äô workflow</li> <li>Clicking on the link provided in the ‚Äòdeploy‚Äô box</li> </ol> <div style="text-align: center;"> <img src="/assets/img/posts/mkdocs-guide/website-build.png" alt="Build Website" width="750"/> </div> <p><br/></p> <p>And voila, your website is now hosted on GitHub Pages!</p> <div style="text-align: center;"> <img src="/assets/img/posts/mkdocs-guide/website-working.png" alt="Working Website" width="700"/> </div> <p><br/></p> <p>Note that the website‚Äôs URL will follow the general structure of <code class="language-plaintext highlighter-rouge">https://username.github.io/repository-name</code>.</p> <p>In Part 2, I will cover how to customise your website using MkDocs, including developing your website‚Äôs structure, adding notes and other media, as well as other fun stuff!</p>]]></content><author><name></name></author><category term="tutorials"/><category term="MkDocs,"/><category term="GitHub,"/><category term="git,"/><category term="open-source,"/><category term="education"/><summary type="html"><![CDATA[How to build a website using MkDocs, and then host it online freely using GitHub Pages]]></summary></entry><entry><title type="html">A memorable summer of schools</title><link href="https://sohaamir.github.io/blog/2024/a_memorable_summer/" rel="alternate" type="text/html" title="A memorable summer of schools"/><published>2024-10-02T20:20:00+00:00</published><updated>2024-10-02T20:20:00+00:00</updated><id>https://sohaamir.github.io/blog/2024/a_memorable_summer</id><content type="html" xml:base="https://sohaamir.github.io/blog/2024/a_memorable_summer/"><![CDATA[<p>One of the hallmarks of doing a PhD is having the opportunity to travel and to network with others in the field. With this in mind, I aplied to three summer schools, the <a href="https://www.compsoccog.com/">Birmingham-Leiden Summer School on Computational Social Cognition</a> (Birmingham, UK), the <a href="https://sites.uci.edu/cmmc/">Computational Modeling of Cognition in a Social Context</a> (Hinterstoder, Austria), and <a href="https://neurobridges.net/">NeuroBridges</a> (Cluny, France). Whilst I was virtually guaranteed to get a place in Birmingham, I honestly did not expect to get a place in either the CMMC or NeuroBridges, both being well-known and internationally competitive. So, it was a nice surprise to be accepted onto all three!</p> <p>(At the same time, I also applied to the <a href="https://www.alpbach.org/">European Forum Alpbach</a> as a Scholarship Holder again, not expecting to be accepted, but was also successful there as well, being only one of ~300 Scholars from over 7,000 applicants!)</p> <p>The Birmingham-Leiden summer school was a great mix between stimulating keynotes, engaging practicals and fun socials! The diversity and scope of the attendees also demonstrated the reputation that Birmingham and Leiden have in the field of computational social neuroscience. Traveling to Austria, the CMMC was the most challenging of the three, but also the most rewarding in terms of gaining skills in computational modeling. The tutorials were highly practical, and whilst toiling away into the late hours debugging my Stan code was not rewarding at the time, I now see the benefits in my development as a budding computational neuroscientist.</p> <p>Finally, attending NeuroBridges in France was something a bit different from the conventional summer school. Intended by <a href="https://www.ab.mpg.de/person/111828/2736">Ahmed El Hady</a> and <a href="https://elsc.huji.ac.il/people-directory/faculty-members/yonatan-loewenstein/">Yonatan Loewenstein</a> to be a bridge between Israeli and Arab students in times of political distress, it has a central theme around decision-making, with lectures from leading experts in a variety of disciplines including molecular biology, neuroscience, psychology and economics. Beyond the curriculum and projects, there were plenty of social activities for attendees and instructors to get to know each other. Whilst the tragic situation in the Middle East worsened day-by-day, we hardly discussed this, instead being far more interested in learning about others‚Äô diverse cultures and histories. A demonstrative example that science and intrigue transcends all cultures, religions and ethnicities.</p> <p>It was a truly great summer, and I hope to continue developing the friendships made with all of the amazing people I met.</p> <p>Aamir</p> <p><br/> <br/></p> <div style="text-align: center;"> <img src="/assets/img/posts/summer_school/birmingham.jpg" alt="birmingham" width="700" height="400"/> </div> <div style="text-align: center;"> <em>Attendees of the Birmingham-Leiden Summer School 2024 (Birmingham, UK).<br/> I'm midway on the left hand side at the back!</em> </div> <p><br/> <br/></p> <div style="text-align: center;"> <img src="/assets/img/posts/summer_school/austria.jpg" alt="austria" width="700" height="500"/> </div> <div style="text-align: center;"> <em>Attendees of the Computational Modeling of Cognition in a Social Context 2024 (Hinterstoder, Austria).<br/> Again, just to the left at the back row!</em> </div> <p><br/> <br/></p> <div style="text-align: center;"> <img src="/assets/img/posts/summer_school/neurobridges.jpeg" alt="neurobridges" width="650" height="420"/> </div> <div style="text-align: center;"> <em>Campus Arts et M√©tiers de Cluny, where NeuroBridges is held.</em> </div>]]></content><author><name></name></author><category term="blogs"/><category term="summer"/><category term="school,"/><category term="PhD,"/><category term="travelling"/><summary type="html"><![CDATA[Three summer schools, a conference and a forum]]></summary></entry><entry><title type="html">Doing outreach with local schools through STEM Ambassadors</title><link href="https://sohaamir.github.io/blog/2024/stem_outreach/" rel="alternate" type="text/html" title="Doing outreach with local schools through STEM Ambassadors"/><published>2024-05-11T13:56:00+00:00</published><updated>2024-05-11T13:56:00+00:00</updated><id>https://sohaamir.github.io/blog/2024/stem_outreach</id><content type="html" xml:base="https://sohaamir.github.io/blog/2024/stem_outreach/"><![CDATA[<p>I have always been passionate about increasing diversity in science, in particular towards those from socioeconomic areas that are currently underrepresented. Whilst there are a number of outreach schemes, <a href="https://www.stem.org.uk/stem-ambassadors">STEM Ambassadors</a> in my opinion offers a great framework that works flexibly around the volunteer.</p> <p>Quoting their website, STEM Ambassadors ‚Äòrepresents over 28,000 individuals who offer their time, passion, and energy to visit schools, colleges, higher education institutions, and youth group organisations to deliver requests from teachers and youth group leaders who want to link STEM subjects to the real world of work‚Äô. Now, this isn‚Äôt just limited to students, as anyone can get involved. As part of the scheme, volunteers create their own plan, a presentation, interactive workshop or whatever takes your fancy, which you then advertise on their website. Subsequently, representatives from local schools can contact you expressing their interest and it is up to for you both to work out a time and date that works best. This process works really well, and allows for you (the volunteer) to decide which offers to accept and reject, based on your own preferences.</p> <p>So far I have done two presentations, to Year 9 students at <a href="https://heartlandsacademy.e-act.org.uk/">Heartlands Academy</a> in Nechells, and to sixth-form students at <a href="https://centralstmichaels.ac.uk/">Central St. Michaels Sixth Form</a> in West Bromwich. My approach in providing an interactive presentation with videos and games has proven very popular and I have had a lot of fun doing so and have enjoyed talking with the students and teachers alike.</p> <p>My presentation which you can find on my GitHub <a href="https://github.com/sohaamir/misc_materials/tree/main/presentations">here</a> covers:</p> <ul> <li>Selective attention (demonstrated through Simon and Chabris‚Äô famous inattention experiment featuring a Gorilla)</li> <li>How human brains differ from other primates (featuring a fun working memory task that chimps are extremely good at!)</li> <li>The search for meaning (through the Heider-Simmel animation)</li> <li>Different approaches in neuroimaging (micro vs macro)</li> <li>Magnetic Resonance Imaging (how does it work and what we can do with it)</li> </ul> <p>The chimp memory game and selective attention video in particular seem to go down really well with students.</p> <p>I would certainly recommend STEM Ambassadors for those interested in outreach to local schools!</p> <p><br/></p> <div style="text-align: center;"> <img src="/assets/img/posts/stem_outreach/stem_talk.jpeg" alt="STEM Talk" width="700" height="500"/> <p style="text-align: center;"><em>Literally pointing out the dangers of MRI at Central St Michael's.</em></p> </div> <p><br/></p>]]></content><author><name></name></author><category term="blogs"/><category term="outreach,"/><category term="stem,"/><category term="neuroscience"/><summary type="html"><![CDATA[Giving talks to students at Heartlands Academy and Central St. Michaels Sixth Form]]></summary></entry><entry><title type="html">Forecasting Google Scholar statistics for researchers at the Centre for Human Brain Health</title><link href="https://sohaamir.github.io/blog/2024/citation_forecasting/" rel="alternate" type="text/html" title="Forecasting Google Scholar statistics for researchers at the Centre for Human Brain Health"/><published>2024-03-23T15:35:00+00:00</published><updated>2024-03-23T15:35:00+00:00</updated><id>https://sohaamir.github.io/blog/2024/citation_forecasting</id><content type="html" xml:base="https://sohaamir.github.io/blog/2024/citation_forecasting/"><![CDATA[<p>Note: this guide is also available on the corresponding GitHub <a href="https://github.com/sohaamir/chbh_google_scholar">repository</a>, where all the required code is freely available.</p> <p>This is a detailed guide for performing the extraction and forecasting of Google Scholar data for researchers at the Centre for Human Brain Health (CHBH), University of Birmingham.</p> <p>Specficially, this involves:</p> <ul> <li>Scraping a list of researchers at the CHBH from the CHBH website (using <code class="language-plaintext highlighter-rouge">beautifulsoup4</code> ).</li> <li>Extracting Google Scholar statistics including citation data (using <code class="language-plaintext highlighter-rouge">serpapi</code> ).</li> <li>Forecasting citations for the years 2024, 2025 and 2026 (using <code class="language-plaintext highlighter-rouge">prophet</code>).</li> </ul> <h3 id="extracting-data-from-the-chbh-website">Extracting data from the CHBH website</h3> <p>The first step is to get a list of names for researchers at the CHBH. We could do this in a bunch of different ways, but one way is to use <code class="language-plaintext highlighter-rouge">beautifulsoup4</code> to extract names from six pages on the CHBH website that list senior researchers.</p> <p>Here is how the webpages display the researcher‚Äôs information (six pages in total):</p> <p><img src="/assets/img/posts/citation_forecasting/chbh_website_pis.png" alt="chbh_website_pis" style="width: 100%;"/> <br/> <br/> And here is the code which extract the names <code class="language-plaintext highlighter-rouge">scrape_chbh.py</code> which it iterates over the list of URLs, and extracts names using the BeautifulSoup library to parse the HTML content. Importantly, the script also filters and cleans these names by removing titles like ‚ÄúDr‚Äù and ‚ÄúProfessor‚Äù. <br/></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">requests</span>
<span class="kn">from</span> <span class="n">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
<span class="kn">import</span> <span class="n">json</span>

<span class="k">def</span> <span class="nf">scrape_names_from_page</span><span class="p">(</span><span class="n">url</span><span class="p">):</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
    <span class="n">soup</span> <span class="o">=</span> <span class="nc">BeautifulSoup</span><span class="p">(</span><span class="n">response</span><span class="p">.</span><span class="n">content</span><span class="p">,</span> <span class="sh">'</span><span class="s">html.parser</span><span class="sh">'</span><span class="p">)</span>

    <span class="c1"># Find all elements that contain names - this will need to be customized based on the page's HTML structure
</span>    <span class="n">name_elements</span> <span class="o">=</span> <span class="n">soup</span><span class="p">.</span><span class="nf">find_all</span><span class="p">(</span><span class="sh">'</span><span class="s">h2</span><span class="sh">'</span><span class="p">)</span>  <span class="c1"># Assuming names are within &lt;h2&gt; tags, change as needed
</span>
    <span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="n">elem</span><span class="p">.</span><span class="nf">get_text</span><span class="p">(</span><span class="n">strip</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="n">name_elements</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">names</span>

<span class="c1"># List of URLs to scrape
</span><span class="n">urls</span> <span class="o">=</span> <span class="p">[</span>
    <span class="sh">"</span><span class="s">https://www.birmingham.ac.uk/research/centre-for-human-brain-health/chbh-research-themes/lifespan-and-brain-health</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">https://www.birmingham.ac.uk/research/centre-for-human-brain-health/chbh-research-themes/cognitive-computational-neuroscience</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">https://www.birmingham.ac.uk/research/centre-for-human-brain-health/chbh-research-themes/social-interaction-and-communication</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">https://www.birmingham.ac.uk/research/centre-for-human-brain-health/chbh-research-themes/learning-memory-and-performance</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">https://www.birmingham.ac.uk/research/centre-for-human-brain-health/chbh-research-themes/awareness-consciousness-and-sleep</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">https://www.birmingham.ac.uk/research/centre-for-human-brain-health/chbh-research-themes/neuroimaging-methods-and-ai</span><span class="sh">"</span>
<span class="p">]</span>

<span class="c1"># Initialize an empty set to hold all unique names across themes
</span><span class="n">unique_names</span> <span class="o">=</span> <span class="nf">set</span><span class="p">()</span>

<span class="c1"># Scrape names from each URL
</span><span class="k">for</span> <span class="n">url</span> <span class="ow">in</span> <span class="n">urls</span><span class="p">:</span>
    <span class="n">names</span> <span class="o">=</span> <span class="nf">scrape_names_from_page</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">names</span><span class="p">:</span>
        <span class="k">if</span> <span class="sh">'</span><span class="s">Dr </span><span class="sh">'</span> <span class="ow">in</span> <span class="n">name</span> <span class="ow">or</span> <span class="sh">'</span><span class="s">Professor </span><span class="sh">'</span> <span class="ow">in</span> <span class="n">name</span><span class="p">:</span>
            <span class="c1"># Clean name and add to the set of unique names
</span>            <span class="n">clean_name</span> <span class="o">=</span> <span class="n">name</span><span class="p">.</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'</span><span class="s">Dr </span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'</span><span class="s">Professor </span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">).</span><span class="nf">strip</span><span class="p">()</span>
            <span class="n">unique_names</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="n">clean_name</span><span class="p">)</span>
</code></pre></div></div> <p><br/> This gives us a list of CHBH researchers (<code class="language-plaintext highlighter-rouge">chbh_names.json</code>).</p> <div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"chbh-investigators"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
    </span><span class="s2">"Alan Wing"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Andrea Krott"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Kim Shapiro"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Craig McAllister"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Clare Anderson"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Rachel Upthegrove"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Dietmar Heinke"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Lei Zhang"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Magda Chechlacz"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Joseph Galea"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Massimiliano (Max) Di Luca"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Jennifer Cook"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Matthew Apps"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"KyungMin An"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Katja Kornysheva"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Andrew J. Bremner"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Ali Mazaheri"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Hamid Dehghani"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Damian Cruse"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Patricia Lockwood"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Ned Jenkinson"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Tom Rhys Marshall"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Chris Miall"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Stephane De Brito"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Romy Froemer"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Anna Kowalczyk"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Suzanne Higgs"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Sarah Aldred"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Andrew Bagshaw"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Rickson C. Mesquita"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Martin Wilson"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Davinia Fern√°ndez-Espejo"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Andrew Quinn"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Hyojin Park"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Karen Mullinger"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Arkady Konovalov"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Felipe Orihuela-Espina"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Carmel Mevorach"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Paul Muhle-Karbe"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Clayton Hickey"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Katrien Segaert"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Nick Holmes"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Sam Lucas"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Ole Jensen"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Barbara Pomiechowska"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Jian Liu"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Steven Frisson"</span><span class="w">
  </span><span class="p">]</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div> <p><br/></p> <h2 id="extracting-google-scholar-data-using-serpapi">Extracting Google Scholar data using SerpAPI</h2> <p><a href="https://serpapi.com/">SerpAPI</a> is a tool that provides developers with an API to scrape and parse search engine results pages (SERPs) from various search engines like Google, Bing, and others, automating the process of extracting search data.</p> <p>SerpAPI offers a range of APIs for Google services, including: Google Search API, Google Images API, Google News API, Google Shopping API, and relevant for this exercise, <strong>Google Scholar API</strong>. It has a free tier, but restricts users to only 100 calls per month, so use them wisely!</p> <p><img src="/assets/img/posts/citation_forecasting/serpapi.png" alt="serpapi" style="width: 100%;"/> <br/> <br/> Importantly, SerpAPI works using Google Scholar ID‚Äôs and not on the researchers names. You can see the ID within the URL when on the researchers profile page. For example, Lei Zhang‚Äôs ID is XmnVUTQAAAAJ.</p> <p><img src="/assets/img/posts/citation_forecasting/lei_scholar_id.png" alt="lei_scholar_id" style="width: 100%;"/> <br/> <br/> I could have written a script to extract this for the researchers using SerpAPI, but given that there are 42 of them, and that I am limited to 100 requests per month (and I‚Äôll need at least 42 for the actual extraction), I just decided to do this manually, creating a csv file <code class="language-plaintext highlighter-rouge">names_and_citation_ids.csv</code> which I then filtered by removing those with no Scholar ID. The final data is <code class="language-plaintext highlighter-rouge">filtered_names_and_citations_ids.csv</code> which looks like this:</p> <pre><code class="language-csv">name,citation_id
Alan Wing,JEihq_0AAAAJ
Andrea Krott,Hfg7LVkAAAAJ
Kim Shapiro,RO_OKQwAAAAJ
Craig McAllister,KFT9l3wAAAAJ
Clare Anderson,MHtyzVoAAAAJ
Rachel Upthegrove,Z1kBsNIAAAAJ
Dietmar Heinke,uExP9ScAAAAJ
Lei Zhang,XmnVUTQAAAAJ
Magda Chechlacz,DSIp5Mh1f3oC
Joseph Galea,xVLhU5kAAAAJ
</code></pre> <p><br/></p> <h4 id="extracting-the-citation-statistics">Extracting the Citation statistics</h4> <p>We can now perform the extraction! Here is the important part of the code which does this (<code class="language-plaintext highlighter-rouge">extract_scholar_info.py</code>). You will need to provide your own SerpAPI Key for the script to work! The input for this script comes from the CSV file just created named <code class="language-plaintext highlighter-rouge">filtered_names_and_citation_ids.csv</code>, and loops through each row, performing the extraction on each <code class="language-plaintext highlighter-rouge">citation_id</code>. The script processes these IDs, retrieves the relevant data for each author, and saves this information in a separate JSON file named after the author‚Äôs citation ID.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">serpapi</span>
<span class="kn">import</span> <span class="n">json</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>

<span class="k">def</span> <span class="nf">author_results</span><span class="p">(</span><span class="n">author_id</span><span class="p">):</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Extracting author results for author ID: </span><span class="si">{</span><span class="n">author_id</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

    <span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
        <span class="sh">"</span><span class="s">api_key</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">SERP_API_KEY</span><span class="sh">"</span><span class="p">,</span>  <span class="c1"># Replace with your actual SerpApi API key
</span>        <span class="sh">"</span><span class="s">engine</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">google_scholar_author</span><span class="sh">"</span><span class="p">,</span>  <span class="c1"># Author results search engine
</span>        <span class="sh">"</span><span class="s">author_id</span><span class="sh">"</span><span class="p">:</span> <span class="n">author_id</span><span class="p">,</span>  <span class="c1"># Author ID as function input
</span>        <span class="sh">"</span><span class="s">hl</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">en</span><span class="sh">"</span>
    <span class="p">}</span>
    
    <span class="n">search</span> <span class="o">=</span> <span class="n">serpapi</span><span class="p">.</span><span class="nf">search</span><span class="p">(</span><span class="n">params</span><span class="p">)</span> 
    <span class="n">results</span> <span class="o">=</span> <span class="n">search</span>  <span class="c1"># Directly use the 'results'
</span>
    <span class="c1"># Extract the necessary information
</span>    <span class="n">thumbnail</span> <span class="o">=</span> <span class="n">results</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="sh">"</span><span class="s">author</span><span class="sh">"</span><span class="p">,</span> <span class="p">{}).</span><span class="nf">get</span><span class="p">(</span><span class="sh">"</span><span class="s">thumbnail</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">name</span> <span class="o">=</span> <span class="n">results</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="sh">"</span><span class="s">author</span><span class="sh">"</span><span class="p">,</span> <span class="p">{}).</span><span class="nf">get</span><span class="p">(</span><span class="sh">"</span><span class="s">name</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">affiliations</span> <span class="o">=</span> <span class="n">results</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="sh">"</span><span class="s">author</span><span class="sh">"</span><span class="p">,</span> <span class="p">{}).</span><span class="nf">get</span><span class="p">(</span><span class="sh">"</span><span class="s">affiliations</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">email</span> <span class="o">=</span> <span class="n">results</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="sh">"</span><span class="s">author</span><span class="sh">"</span><span class="p">,</span> <span class="p">{}).</span><span class="nf">get</span><span class="p">(</span><span class="sh">"</span><span class="s">email</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">website</span> <span class="o">=</span> <span class="n">results</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="sh">"</span><span class="s">author</span><span class="sh">"</span><span class="p">,</span> <span class="p">{}).</span><span class="nf">get</span><span class="p">(</span><span class="sh">"</span><span class="s">website</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">interests</span> <span class="o">=</span> <span class="n">results</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="sh">"</span><span class="s">author</span><span class="sh">"</span><span class="p">,</span> <span class="p">{}).</span><span class="nf">get</span><span class="p">(</span><span class="sh">"</span><span class="s">interests</span><span class="sh">"</span><span class="p">)</span>
    
    <span class="n">cited_by_table</span> <span class="o">=</span> <span class="n">results</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="sh">"</span><span class="s">cited_by</span><span class="sh">"</span><span class="p">,</span> <span class="p">{}).</span><span class="nf">get</span><span class="p">(</span><span class="sh">"</span><span class="s">table</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">cited_by_graph</span> <span class="o">=</span> <span class="n">results</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="sh">"</span><span class="s">cited_by</span><span class="sh">"</span><span class="p">,</span> <span class="p">{}).</span><span class="nf">get</span><span class="p">(</span><span class="sh">"</span><span class="s">graph</span><span class="sh">"</span><span class="p">)</span>
    
    <span class="n">public_access_link</span> <span class="o">=</span> <span class="n">results</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="sh">"</span><span class="s">public_access</span><span class="sh">"</span><span class="p">,</span> <span class="p">{}).</span><span class="nf">get</span><span class="p">(</span><span class="sh">"</span><span class="s">link</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">available_public_access</span> <span class="o">=</span> <span class="n">results</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="sh">"</span><span class="s">public_access</span><span class="sh">"</span><span class="p">,</span> <span class="p">{}).</span><span class="nf">get</span><span class="p">(</span><span class="sh">"</span><span class="s">available</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">not_available_public_access</span> <span class="o">=</span> <span class="n">results</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="sh">"</span><span class="s">public_access</span><span class="sh">"</span><span class="p">,</span> <span class="p">{}).</span><span class="nf">get</span><span class="p">(</span><span class="sh">"</span><span class="s">not_available</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">co_authors</span> <span class="o">=</span> <span class="n">results</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="sh">"</span><span class="s">co_authors</span><span class="sh">"</span><span class="p">)</span>
    
    <span class="n">author_results_data</span> <span class="o">=</span> <span class="p">{</span>
      <span class="sh">"</span><span class="s">thumbnail</span><span class="sh">"</span><span class="p">:</span> <span class="n">thumbnail</span><span class="p">,</span>
      <span class="sh">"</span><span class="s">name</span><span class="sh">"</span><span class="p">:</span> <span class="n">name</span><span class="p">,</span>
      <span class="sh">"</span><span class="s">affiliations</span><span class="sh">"</span><span class="p">:</span> <span class="n">affiliations</span><span class="p">,</span>
      <span class="sh">"</span><span class="s">email</span><span class="sh">"</span><span class="p">:</span> <span class="n">email</span><span class="p">,</span>
      <span class="sh">"</span><span class="s">website</span><span class="sh">"</span><span class="p">:</span> <span class="n">website</span><span class="p">,</span>
      <span class="sh">"</span><span class="s">interests</span><span class="sh">"</span><span class="p">:</span> <span class="n">interests</span><span class="p">,</span>
      <span class="sh">"</span><span class="s">cited_by_table</span><span class="sh">"</span><span class="p">:</span> <span class="n">cited_by_table</span><span class="p">,</span>
      <span class="sh">"</span><span class="s">cited_by_graph</span><span class="sh">"</span><span class="p">:</span> <span class="n">cited_by_graph</span><span class="p">,</span>
      <span class="sh">"</span><span class="s">public_access_link</span><span class="sh">"</span><span class="p">:</span> <span class="n">public_access_link</span><span class="p">,</span>
      <span class="sh">"</span><span class="s">available_public_access</span><span class="sh">"</span><span class="p">:</span> <span class="n">available_public_access</span><span class="p">,</span>
      <span class="sh">"</span><span class="s">not_available_public_access</span><span class="sh">"</span><span class="p">:</span> <span class="n">not_available_public_access</span><span class="p">,</span>
      <span class="sh">"</span><span class="s">co_authors</span><span class="sh">"</span><span class="p">:</span> <span class="n">co_authors</span>
    <span class="p">}</span>
    
    <span class="c1"># Save the data to a JSON file named after the author_id
</span>    <span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">author_id</span><span class="si">}</span><span class="s">.json</span><span class="sh">"</span><span class="p">,</span> <span class="sh">'</span><span class="s">w</span><span class="sh">'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="sh">'</span><span class="s">utf-8</span><span class="sh">'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">json</span><span class="p">.</span><span class="nf">dump</span><span class="p">(</span><span class="n">author_results_data</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">ensure_ascii</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
    
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Data saved to </span><span class="si">{</span><span class="n">author_id</span><span class="si">}</span><span class="s">.json</span><span class="sh">"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">author_results_data</span> 
</code></pre></div></div> <p>The individual JSON files contains information contained within one‚Äôs Scholar Page. We can do a whole range of potential analyses, but we are interested in just using the citation statistics for now.</p> <p><img src="/assets/img/posts/citation_forecasting/pat_scholar_profile.png" alt="pat_scholar_profile" style="width: 100%;"/></p> <div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
    </span><span class="nl">"thumbnail"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https://scholar.googleusercontent.com/citations?view_op=view_photo&amp;user=ynN6pG0AAAAJ&amp;citpid=9"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Patricia Lockwood"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"affiliations"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Associate Professor, Sir Henry Dale Fellow &amp; Jacobs Fellow, University of Birmingham"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"email"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Verified email at bham.ac.uk"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"website"</span><span class="p">:</span><span class="w"> </span><span class="s2">"http://www.sdn-lab.org/"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"interests"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
        </span><span class="p">{</span><span class="w">
            </span><span class="nl">"title"</span><span class="p">:</span><span class="w"> </span><span class="s2">"cognitive neuroscience"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"link"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https://scholar.google.com/citations?view_op=search_authors&amp;hl=en&amp;mauthors=label:cognitive_neuroscience"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"serpapi_link"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https://serpapi.com/search.json?engine=google_scholar_profiles&amp;hl=en&amp;mauthors=label%3Acognitive_neuroscience"</span><span class="w">
        </span><span class="p">},</span><span class="w">
        </span><span class="p">{</span><span class="w">
            </span><span class="nl">"title"</span><span class="p">:</span><span class="w"> </span><span class="s2">"social neuroscience"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"link"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https://scholar.google.com/citations?view_op=search_authors&amp;hl=en&amp;mauthors=label:social_neuroscience"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"serpapi_link"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https://serpapi.com/search.json?engine=google_scholar_profiles&amp;hl=en&amp;mauthors=label%3Asocial_neuroscience"</span><span class="w">
        </span><span class="p">},</span><span class="w">
        </span><span class="p">{</span><span class="w">
            </span><span class="nl">"title"</span><span class="p">:</span><span class="w"> </span><span class="s2">"decision neuroscience"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"link"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https://scholar.google.com/citations?view_op=search_authors&amp;hl=en&amp;mauthors=label:decision_neuroscience"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"serpapi_link"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https://serpapi.com/search.json?engine=google_scholar_profiles&amp;hl=en&amp;mauthors=label%3Adecision_neuroscience"</span><span class="w">
        </span><span class="p">},</span><span class="w">
        </span><span class="p">{</span><span class="w">
            </span><span class="nl">"title"</span><span class="p">:</span><span class="w"> </span><span class="s2">"learning"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"link"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https://scholar.google.com/citations?view_op=search_authors&amp;hl=en&amp;mauthors=label:learning"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"serpapi_link"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https://serpapi.com/search.json?engine=google_scholar_profiles&amp;hl=en&amp;mauthors=label%3Alearning"</span><span class="w">
        </span><span class="p">},</span><span class="w">
        </span><span class="p">{</span><span class="w">
            </span><span class="nl">"title"</span><span class="p">:</span><span class="w"> </span><span class="s2">"lifespan"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"link"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https://scholar.google.com/citations?view_op=search_authors&amp;hl=en&amp;mauthors=label:lifespan"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"serpapi_link"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https://serpapi.com/search.json?engine=google_scholar_profiles&amp;hl=en&amp;mauthors=label%3Alifespan"</span><span class="w">
        </span><span class="p">}</span><span class="w">
    </span><span class="p">],</span><span class="w">
    </span><span class="nl">"cited_by_table"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
        </span><span class="p">{</span><span class="w">
            </span><span class="nl">"citations"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
                </span><span class="nl">"all"</span><span class="p">:</span><span class="w"> </span><span class="mi">4773</span><span class="p">,</span><span class="w">
                </span><span class="nl">"since_2019"</span><span class="p">:</span><span class="w"> </span><span class="mi">3566</span><span class="w">
            </span><span class="p">}</span><span class="w">
        </span><span class="p">},</span><span class="w">
        </span><span class="p">{</span><span class="w">
            </span><span class="nl">"h_index"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
                </span><span class="nl">"all"</span><span class="p">:</span><span class="w"> </span><span class="mi">29</span><span class="p">,</span><span class="w">
                </span><span class="nl">"since_2019"</span><span class="p">:</span><span class="w"> </span><span class="mi">29</span><span class="w">
            </span><span class="p">}</span><span class="w">
        </span><span class="p">},</span><span class="w">
        </span><span class="p">{</span><span class="w">
            </span><span class="nl">"i10_index"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
                </span><span class="nl">"all"</span><span class="p">:</span><span class="w"> </span><span class="mi">41</span><span class="p">,</span><span class="w">
                </span><span class="nl">"since_2019"</span><span class="p">:</span><span class="w"> </span><span class="mi">40</span><span class="w">
            </span><span class="p">}</span><span class="w">
        </span><span class="p">}</span><span class="w">
    </span><span class="p">],</span><span class="w">
    </span><span class="nl">"cited_by_graph"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
        </span><span class="p">{</span><span class="w">
            </span><span class="nl">"year"</span><span class="p">:</span><span class="w"> </span><span class="mi">2013</span><span class="p">,</span><span class="w">
            </span><span class="nl">"citations"</span><span class="p">:</span><span class="w"> </span><span class="mi">40</span><span class="w">
        </span><span class="p">},</span><span class="w">
        </span><span class="p">{</span><span class="w">
            </span><span class="nl">"year"</span><span class="p">:</span><span class="w"> </span><span class="mi">2014</span><span class="p">,</span><span class="w">
            </span><span class="nl">"citations"</span><span class="p">:</span><span class="w"> </span><span class="mi">103</span><span class="w">
        </span><span class="p">},</span><span class="w">
        </span><span class="p">{</span><span class="w">
            </span><span class="nl">"year"</span><span class="p">:</span><span class="w"> </span><span class="mi">2015</span><span class="p">,</span><span class="w">
            </span><span class="nl">"citations"</span><span class="p">:</span><span class="w"> </span><span class="mi">126</span><span class="w">
        </span><span class="p">},</span><span class="w">
        </span><span class="p">{</span><span class="w">
            </span><span class="nl">"year"</span><span class="p">:</span><span class="w"> </span><span class="mi">2016</span><span class="p">,</span><span class="w">
            </span><span class="nl">"citations"</span><span class="p">:</span><span class="w"> </span><span class="mi">214</span><span class="w">
        </span><span class="p">},</span><span class="w">
        </span><span class="p">{</span><span class="w">
            </span><span class="nl">"year"</span><span class="p">:</span><span class="w"> </span><span class="mi">2017</span><span class="p">,</span><span class="w">
            </span><span class="nl">"citations"</span><span class="p">:</span><span class="w"> </span><span class="mi">289</span><span class="w">
        </span><span class="p">},</span><span class="w">
        </span><span class="p">{</span><span class="w">
            </span><span class="nl">"year"</span><span class="p">:</span><span class="w"> </span><span class="mi">2018</span><span class="p">,</span><span class="w">
            </span><span class="nl">"citations"</span><span class="p">:</span><span class="w"> </span><span class="mi">396</span><span class="w">
        </span><span class="p">},</span><span class="w">
        </span><span class="p">{</span><span class="w">
            </span><span class="nl">"year"</span><span class="p">:</span><span class="w"> </span><span class="mi">2019</span><span class="p">,</span><span class="w">
            </span><span class="nl">"citations"</span><span class="p">:</span><span class="w"> </span><span class="mi">342</span><span class="w">
        </span><span class="p">},</span><span class="w">
        </span><span class="p">{</span><span class="w">
            </span><span class="nl">"year"</span><span class="p">:</span><span class="w"> </span><span class="mi">2020</span><span class="p">,</span><span class="w">
            </span><span class="nl">"citations"</span><span class="p">:</span><span class="w"> </span><span class="mi">431</span><span class="w">
        </span><span class="p">},</span><span class="w">
        </span><span class="p">{</span><span class="w">
            </span><span class="nl">"year"</span><span class="p">:</span><span class="w"> </span><span class="mi">2021</span><span class="p">,</span><span class="w">
            </span><span class="nl">"citations"</span><span class="p">:</span><span class="w"> </span><span class="mi">776</span><span class="w">
        </span><span class="p">},</span><span class="w">
        </span><span class="p">{</span><span class="w">
            </span><span class="nl">"year"</span><span class="p">:</span><span class="w"> </span><span class="mi">2022</span><span class="p">,</span><span class="w">
            </span><span class="nl">"citations"</span><span class="p">:</span><span class="w"> </span><span class="mi">874</span><span class="w">
        </span><span class="p">},</span><span class="w">
        </span><span class="p">{</span><span class="w">
            </span><span class="nl">"year"</span><span class="p">:</span><span class="w"> </span><span class="mi">2023</span><span class="p">,</span><span class="w">
            </span><span class="nl">"citations"</span><span class="p">:</span><span class="w"> </span><span class="mi">924</span><span class="w">
        </span><span class="p">},</span><span class="w">
        </span><span class="p">{</span><span class="w">
            </span><span class="nl">"year"</span><span class="p">:</span><span class="w"> </span><span class="mi">2024</span><span class="p">,</span><span class="w">
            </span><span class="nl">"citations"</span><span class="p">:</span><span class="w"> </span><span class="mi">200</span><span class="w">
        </span><span class="p">}</span><span class="w">
    </span><span class="p">],</span><span class="w">
    </span><span class="nl">"public_access_link"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https://scholar.google.com/citations?view_op=list_mandates&amp;hl=en&amp;user=ynN6pG0AAAAJ"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"available_public_access"</span><span class="p">:</span><span class="w"> </span><span class="mi">59</span><span class="p">,</span><span class="w">
    </span><span class="nl">"not_available_public_access"</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w">
    </span><span class="nl">"co_authors"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
        </span><span class="p">{</span><span class="w">
            </span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Matthew Apps"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"link"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https://scholar.google.com/citations?user=ZTqTFbwAAAAJ&amp;hl=en"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"serpapi_link"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https://serpapi.com/search.json?author_id=ZTqTFbwAAAAJ&amp;engine=google_scholar_author&amp;hl=en"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"author_id"</span><span class="p">:</span><span class="w"> </span><span class="s2">"ZTqTFbwAAAAJ"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"affiliations"</span><span class="p">:</span><span class="w"> </span><span class="s2">"BBSRC Fellow, &amp; Senior Research Fellow (=Associate Professor)"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"email"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Verified email at bham.ac.uk"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"thumbnail"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https://scholar.google.com/citations/images/avatar_scholar_56.png"</span><span class="w">
        </span><span class="p">},</span><span class="w">
        </span><span class="p">{</span><span class="w">
            </span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Essi Viding"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"link"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https://scholar.google.com/citations?user=Ydwv2DYAAAAJ&amp;hl=en"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"serpapi_link"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https://serpapi.com/search.json?author_id=Ydwv2DYAAAAJ&amp;engine=google_scholar_author&amp;hl=en"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"author_id"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Ydwv2DYAAAAJ"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"affiliations"</span><span class="p">:</span><span class="w"> </span><span class="s2">"UCL"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"email"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Verified email at ucl.ac.uk"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"thumbnail"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=Ydwv2DYAAAAJ&amp;citpid=13"</span><span class="w">
        </span><span class="p">},</span><span class="w">
        </span><span class="p">{</span><span class="w">
            </span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Masud Husain"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"link"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https://scholar.google.com/citations?user=_GXoXKMAAAAJ&amp;hl=en"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"serpapi_link"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https://serpapi.com/search.json?author_id=_GXoXKMAAAAJ&amp;engine=google_scholar_author&amp;hl=en"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"author_id"</span><span class="p">:</span><span class="w"> </span><span class="s2">"_GXoXKMAAAAJ"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"affiliations"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Professor of Neurology &amp; Cognitive Neuroscience, Oxford. Editor-in-Chief, Brain"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"email"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Verified email at ndcn.ox.ac.uk"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"thumbnail"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=_GXoXKMAAAAJ&amp;citpid=34"</span><span class="w">
        </span><span class="p">},</span><span class="w">
  </span><span class="err">(and</span><span class="w"> </span><span class="err">so</span><span class="w"> </span><span class="err">on)</span><span class="w">
    </span><span class="p">]</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div> <p>We can then simply extract this data across all JSON files by running <code class="language-plaintext highlighter-rouge">processing_citation_data.py</code></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">os</span>
<span class="kn">import</span> <span class="n">json</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>

<span class="c1"># List all JSON files in the current directory
</span><span class="n">json_files</span> <span class="o">=</span> <span class="p">[</span><span class="n">f</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">os</span><span class="p">.</span><span class="nf">listdir</span><span class="p">(</span><span class="sh">'</span><span class="s">.</span><span class="sh">'</span><span class="p">)</span> <span class="k">if</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">isfile</span><span class="p">(</span><span class="n">f</span><span class="p">)</span> <span class="ow">and</span> <span class="n">f</span><span class="p">.</span><span class="nf">endswith</span><span class="p">(</span><span class="sh">'</span><span class="s">.json</span><span class="sh">'</span><span class="p">)]</span>

<span class="c1"># Initialize a list to store data for each author
</span><span class="n">authors_data</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Process each JSON file
</span><span class="k">for</span> <span class="n">filename</span> <span class="ow">in</span> <span class="n">json_files</span><span class="p">:</span>
    <span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="sh">'</span><span class="s">r</span><span class="sh">'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="sh">'</span><span class="s">utf-8</span><span class="sh">'</span><span class="p">)</span> <span class="k">as</span> <span class="nb">file</span><span class="p">:</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">json</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="nb">file</span><span class="p">)</span>
        
        <span class="c1"># Extracting required information
</span>        <span class="n">name</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="sh">'</span><span class="s">name</span><span class="sh">'</span><span class="p">]</span>
        <span class="n">citations_all</span> <span class="o">=</span> <span class="nf">next</span><span class="p">((</span><span class="n">item</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">data</span><span class="p">[</span><span class="sh">'</span><span class="s">cited_by_table</span><span class="sh">'</span><span class="p">]</span> <span class="k">if</span> <span class="sh">'</span><span class="s">citations</span><span class="sh">'</span> <span class="ow">in</span> <span class="n">item</span><span class="p">),</span> <span class="p">{}).</span><span class="nf">get</span><span class="p">(</span><span class="sh">'</span><span class="s">citations</span><span class="sh">'</span><span class="p">,</span> <span class="p">{}).</span><span class="nf">get</span><span class="p">(</span><span class="sh">'</span><span class="s">all</span><span class="sh">'</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">h_index_all</span> <span class="o">=</span> <span class="nf">next</span><span class="p">((</span><span class="n">item</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">data</span><span class="p">[</span><span class="sh">'</span><span class="s">cited_by_table</span><span class="sh">'</span><span class="p">]</span> <span class="k">if</span> <span class="sh">'</span><span class="s">h_index</span><span class="sh">'</span> <span class="ow">in</span> <span class="n">item</span><span class="p">),</span> <span class="p">{}).</span><span class="nf">get</span><span class="p">(</span><span class="sh">'</span><span class="s">h_index</span><span class="sh">'</span><span class="p">,</span> <span class="p">{}).</span><span class="nf">get</span><span class="p">(</span><span class="sh">'</span><span class="s">all</span><span class="sh">'</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">i10_index_all</span> <span class="o">=</span> <span class="nf">next</span><span class="p">((</span><span class="n">item</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">data</span><span class="p">[</span><span class="sh">'</span><span class="s">cited_by_table</span><span class="sh">'</span><span class="p">]</span> <span class="k">if</span> <span class="sh">'</span><span class="s">i10_index</span><span class="sh">'</span> <span class="ow">in</span> <span class="n">item</span><span class="p">),</span> <span class="p">{}).</span><span class="nf">get</span><span class="p">(</span><span class="sh">'</span><span class="s">i10_index</span><span class="sh">'</span><span class="p">,</span> <span class="p">{}).</span><span class="nf">get</span><span class="p">(</span><span class="sh">'</span><span class="s">all</span><span class="sh">'</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        
        <span class="c1"># Initialize a dict for the author's citation years data
</span>        <span class="n">citation_years</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">name</span><span class="sh">'</span><span class="p">:</span> <span class="n">name</span><span class="p">,</span> <span class="sh">'</span><span class="s">citations</span><span class="sh">'</span><span class="p">:</span> <span class="n">citations_all</span><span class="p">,</span> <span class="sh">'</span><span class="s">h-index</span><span class="sh">'</span><span class="p">:</span> <span class="n">h_index_all</span><span class="p">,</span> <span class="sh">'</span><span class="s">i10-index</span><span class="sh">'</span><span class="p">:</span> <span class="n">i10_index_all</span><span class="p">}</span>
        
        <span class="c1"># Add citation count per year to the dict
</span>        <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">data</span><span class="p">[</span><span class="sh">'</span><span class="s">cited_by_graph</span><span class="sh">'</span><span class="p">]:</span>
            <span class="n">year</span> <span class="o">=</span> <span class="n">item</span><span class="p">[</span><span class="sh">'</span><span class="s">year</span><span class="sh">'</span><span class="p">]</span>
            <span class="n">citations</span> <span class="o">=</span> <span class="n">item</span><span class="p">[</span><span class="sh">'</span><span class="s">citations</span><span class="sh">'</span><span class="p">]</span>
            <span class="n">citation_years</span><span class="p">[</span><span class="sa">f</span><span class="sh">'</span><span class="s">citations_</span><span class="si">{</span><span class="n">year</span><span class="si">}</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">citations</span>
        
        <span class="c1"># Append the author's data to the list
</span>        <span class="n">authors_data</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">citation_years</span><span class="p">)</span>

<span class="c1"># Convert the list of data into a DataFrame
</span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">authors_data</span><span class="p">)</span>

<span class="c1"># Fill NaN values with 0 to indicate years without citations
</span><span class="n">df</span><span class="p">.</span><span class="nf">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># Save the DataFrame to a CSV file
</span><span class="n">df</span><span class="p">.</span><span class="nf">to_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">../data/citations_statistics/citation_statistics.csv</span><span class="sh">'</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="sh">'</span><span class="s">utf-8</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <p>Which creates the <code class="language-plaintext highlighter-rouge">citation_statistics.csv</code>, containing all the citation statistics for all researchers! <br/> <br/></p> <h3 id="forecasting-future-citations-using-prophet">Forecasting future citations using Prophet</h3> <p>There are many different approaches we can use to forecast the number of citations a researcher will get in the future. I will be using <code class="language-plaintext highlighter-rouge">prophet</code>, a open-source forecasting tool developed by Facebook and designed for ease of use and handling the complexities of daily, weekly, and yearly seasonal patterns.</p> <blockquote> <p>Note, that I am not using Prophet because it‚Äôs the most accurate or even the most suitable for this data, I just wanted to try it out!</p> </blockquote> <h4 id="working-with-the-jupyter-notebook-for-plotting">Working with the Jupyter Notebook for plotting</h4> <p>The code for subsetting the data, forecasting and plotting the forecasted plots are available in <code class="language-plaintext highlighter-rouge">plotting_chbh_statistics.ipynb</code>.</p> <p>You will need to install a kernel for Jupyter Notebooks within the virtual environment:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">ipykernel</span> <span class="n">install</span> <span class="o">--</span><span class="n">user</span> <span class="o">--</span><span class="n">name</span><span class="o">=</span><span class="p">.</span><span class="n">venv</span>
</code></pre></div></div> <p>and then can run the Jupyter Notebook.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">notebook</span>
</code></pre></div></div> <p>The notebook firstly plots the csv data as is, generating citation numbers over time for all researchers:</p> <p><img src="/assets/img/posts/citation_forecasting/citations_plot.png" alt="chbh_citations" style="width:100%;"/></p> <p>We can then run our predictive model. This function processes the citation data to fit the <code class="language-plaintext highlighter-rouge">prophet</code> model, predicts citations for the years 2024, 2025, and 2026, and returns these predictions. After applying the forecasting function to each row in the dataset, the script calculates cumulative citations for each year, including the forecasted years, and appends these cumulative citations to the original dataset.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">from</span> <span class="n">prophet</span> <span class="kn">import</span> <span class="n">Prophet</span>

<span class="c1"># Load the data from the CSV file
</span><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">../data/citation_stats/citation_statistics.csv</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># Remove the 'citations_2024' column
</span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">citations_2024</span><span class="sh">'</span><span class="p">])</span>

<span class="c1"># Function to perform forecasting for each person
</span><span class="k">def</span> <span class="nf">forecast_citations</span><span class="p">(</span><span class="n">row</span><span class="p">):</span>
    <span class="c1"># Extract the relevant citation columns
</span>    <span class="n">citation_cols</span> <span class="o">=</span> <span class="p">[</span><span class="n">col</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">row</span><span class="p">.</span><span class="n">index</span> <span class="k">if</span> <span class="n">col</span><span class="p">.</span><span class="nf">startswith</span><span class="p">(</span><span class="sh">'</span><span class="s">citations_</span><span class="sh">'</span><span class="p">)]</span>
    
    <span class="c1"># Create a dataframe with the citation data
</span>    <span class="n">citation_data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">({</span><span class="sh">'</span><span class="s">ds</span><span class="sh">'</span><span class="p">:</span> <span class="n">citation_cols</span><span class="p">,</span> <span class="sh">'</span><span class="s">y</span><span class="sh">'</span><span class="p">:</span> <span class="n">row</span><span class="p">[</span><span class="n">citation_cols</span><span class="p">]})</span>
    
    <span class="c1"># Remove rows with zero citations
</span>    <span class="n">citation_data</span> <span class="o">=</span> <span class="n">citation_data</span><span class="p">[</span><span class="n">citation_data</span><span class="p">[</span><span class="sh">'</span><span class="s">y</span><span class="sh">'</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">]</span>
    
    <span class="c1"># Convert the 'ds' column to datetime by extracting the year from the column name
</span>    <span class="n">citation_data</span><span class="p">[</span><span class="sh">'</span><span class="s">ds</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">to_datetime</span><span class="p">(</span><span class="n">citation_data</span><span class="p">[</span><span class="sh">'</span><span class="s">ds</span><span class="sh">'</span><span class="p">].</span><span class="nb">str</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">'</span><span class="s">_</span><span class="sh">'</span><span class="p">).</span><span class="nb">str</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="nb">format</span><span class="o">=</span><span class="sh">'</span><span class="s">%Y</span><span class="sh">'</span><span class="p">)</span>
    
    <span class="c1"># Create a Prophet model
</span>    <span class="n">model</span> <span class="o">=</span> <span class="nc">Prophet</span><span class="p">()</span>
    
    <span class="c1"># Fit the model to the citation data
</span>    <span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">citation_data</span><span class="p">)</span>
    
    <span class="c1"># Generate future dates for forecasting
</span>    <span class="n">future_dates</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">({</span><span class="sh">'</span><span class="s">ds</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="sh">'</span><span class="s">2024-01-01</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">2025-01-01</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">2026-01-01</span><span class="sh">'</span><span class="p">]})</span>
    
    <span class="c1"># Make predictions for the future dates
</span>    <span class="n">forecast</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">future_dates</span><span class="p">)</span>
    
    <span class="c1"># Extract the forecasted values
</span>    <span class="n">predicted_values</span> <span class="o">=</span> <span class="n">forecast</span><span class="p">[</span><span class="sh">'</span><span class="s">yhat</span><span class="sh">'</span><span class="p">].</span><span class="n">values</span>
    
    <span class="k">return</span> <span class="n">pd</span><span class="p">.</span><span class="nc">Series</span><span class="p">(</span><span class="n">predicted_values</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">prediction_2024</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">prediction_2025</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">prediction_2026</span><span class="sh">'</span><span class="p">])</span>

<span class="c1"># Apply the forecasting function to each row
</span><span class="n">data</span><span class="p">[[</span><span class="sh">'</span><span class="s">prediction_2024</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">prediction_2025</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">prediction_2026</span><span class="sh">'</span><span class="p">]]</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="n">forecast_citations</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Get the citation columns
</span><span class="n">citation_cols</span> <span class="o">=</span> <span class="p">[</span><span class="n">col</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">data</span><span class="p">.</span><span class="n">columns</span> <span class="k">if</span> <span class="n">col</span><span class="p">.</span><span class="nf">startswith</span><span class="p">(</span><span class="sh">'</span><span class="s">citations_</span><span class="sh">'</span><span class="p">)]</span>

<span class="c1"># Sort the citation columns in ascending order
</span><span class="n">citation_cols</span> <span class="o">=</span> <span class="nf">sorted</span><span class="p">(</span><span class="n">citation_cols</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nf">int</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">'</span><span class="s">_</span><span class="sh">'</span><span class="p">)[</span><span class="mi">1</span><span class="p">]))</span>

<span class="c1"># Create a new DataFrame to store the cumulative citations
</span><span class="n">cumulative_data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="n">data</span><span class="p">.</span><span class="n">index</span><span class="p">)</span>

<span class="c1"># Calculate the cumulative citations for each year
</span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">citation_cols</span><span class="p">)):</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">cumulative_data</span><span class="p">[</span><span class="sa">f</span><span class="sh">'</span><span class="s">cumulative_</span><span class="si">{</span><span class="n">citation_cols</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s">_</span><span class="sh">"</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">citation_cols</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">cumulative_data</span><span class="p">[</span><span class="sa">f</span><span class="sh">'</span><span class="s">cumulative_</span><span class="si">{</span><span class="n">citation_cols</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s">_</span><span class="sh">"</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">cumulative_data</span><span class="p">[</span><span class="sa">f</span><span class="sh">'</span><span class="s">cumulative_</span><span class="si">{</span><span class="n">citation_cols</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s">_</span><span class="sh">"</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="sh">'</span><span class="p">]</span> <span class="o">+</span> <span class="n">data</span><span class="p">[</span><span class="n">citation_cols</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span>

<span class="c1"># Calculate the cumulative citations for the predicted years
</span><span class="n">cumulative_data</span><span class="p">[</span><span class="sh">'</span><span class="s">cumulative_2024</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">cumulative_data</span><span class="p">[</span><span class="sa">f</span><span class="sh">'</span><span class="s">cumulative_</span><span class="si">{</span><span class="n">citation_cols</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s">_</span><span class="sh">"</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="sh">'</span><span class="p">]</span> <span class="o">+</span> <span class="n">data</span><span class="p">[</span><span class="sh">'</span><span class="s">prediction_2024</span><span class="sh">'</span><span class="p">]</span>
<span class="n">cumulative_data</span><span class="p">[</span><span class="sh">'</span><span class="s">cumulative_2025</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">cumulative_data</span><span class="p">[</span><span class="sh">'</span><span class="s">cumulative_2024</span><span class="sh">'</span><span class="p">]</span> <span class="o">+</span> <span class="n">data</span><span class="p">[</span><span class="sh">'</span><span class="s">prediction_2025</span><span class="sh">'</span><span class="p">]</span>
<span class="n">cumulative_data</span><span class="p">[</span><span class="sh">'</span><span class="s">cumulative_2026</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">cumulative_data</span><span class="p">[</span><span class="sh">'</span><span class="s">cumulative_2025</span><span class="sh">'</span><span class="p">]</span> <span class="o">+</span> <span class="n">data</span><span class="p">[</span><span class="sh">'</span><span class="s">prediction_2026</span><span class="sh">'</span><span class="p">]</span>

<span class="c1"># Concatenate the original data with the cumulative citations
</span><span class="n">updated_data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">data</span><span class="p">,</span> <span class="n">cumulative_data</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Save the updated data to the same CSV file
</span><span class="n">updated_data</span><span class="p">.</span><span class="nf">to_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">citation_statistics_with_predictions.csv</span><span class="sh">'</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div></div> <p>After calculating the cumulative citations for the predicted years (2024, 2025 and 2026), we can plot the predicted citation number, as well as the cumulative predicted citations for these years:</p> <p><img src="/assets/img/posts/citation_forecasting/lei_cumulative_plot.png" alt="lei_cumulative_plot" style="width: 100%;"/></p> <p><img src="/assets/img/posts/citation_forecasting/lei_yearly_plot.png" alt="lei_yearly_plot" style="width: 100%;"/></p> <p>These are displayed using <code class="language-plaintext highlighter-rouge">plotly</code> within the Jupyter notebook, which are interactive plots.</p> <h4 id="how-accurate-are-the-predictions">How accurate are the predictions?</h4> <p>It‚Äôs all well to use a model in making some prediction, but how accurate is that model? The final section of the notebook calculates predictions for the year 2023 (the last year where complete yearly citation data are available) and compares this prediction to the actual values across all researchers.</p> <p>Ultimately, the model has an accuracy of <strong>80.63%</strong>, which whilst good, isn‚Äôt great.</p> <p><strong>Congratulations, you just extracted data from a website, ran forecasting models and created interactive plots!</strong></p>]]></content><author><name></name></author><category term="tutorials"/><category term="python,"/><category term="CHBH,"/><category term="forecasting,"/><category term="beautifulsoup4,"/><category term="serpapi,"/><category term="prophet"/><summary type="html"><![CDATA[A detailed guide on how to extract and predict Google Scholar citations using beautifulsoup4, SerpAPI and Prophet]]></summary></entry><entry><title type="html">The evolving concept of diagnostic classification in psychiatry</title><link href="https://sohaamir.github.io/blog/2024/psych_classification/" rel="alternate" type="text/html" title="The evolving concept of diagnostic classification in psychiatry"/><published>2024-01-15T13:56:00+00:00</published><updated>2024-01-15T13:56:00+00:00</updated><id>https://sohaamir.github.io/blog/2024/psych_classification</id><content type="html" xml:base="https://sohaamir.github.io/blog/2024/psych_classification/"><![CDATA[<p><em>Mental health disorders are typically assessed using a broadly defined classification, through diagnostic manuals such as the DSM or ICD. However, this approach has recently been criticised due to its repetitional nature, low descriptive power of patient heterogeneity, and inability to map on to the underlying cognitive mechanisms. In this post I briefly discuss the historical origins of the diagnostic manual, summarise recent alternative frameworks.</em> <br/> <br/></p> <h2 id="a-very-brief-history-of-psychiatry">A (very) brief history of psychiatry</h2> <p>In antiquity, one of the key philosophical questions pertained to how the human body functioned. There were two main schools of thought. The first was the ‚ÄòCardiocentric view‚Äô popularised by Aristotle and endorsed by other prominent Greek thinkers including Diocles and Praxagoras. This view was substantiated by Aristotle on a number of points including ‚Äòthe lack of sense organs‚Äô within the brain, as well as it‚Äôs plain visual appearance and inability of feeling (Frampton, 1991). The second view was the ‚ÄòCephalocentric view‚Äô which posited the brain was instead the primary source of human behaviour and emotion. Interestingly this correct interpretation predates the cardiocentric view, with Alcmaeon of Croton in the 5th century B.C. being the initial proponent. It is for this reason that he is often called the ‚ÄòFather of Neuroscience‚Äô. By extension, he may also be dubbed the ‚ÄòFather of Psychiatry‚Äô in that he also was the first to distinguish a neurological condition as having a non-divine cause. He did so with reference to epilepsy (Debernardi et al., 2010), a view which would influence other prominent Greek physicans including Hippocrates.</p> <p>Moving to the 18th century, a different figurehead, Benjamin Rush (‚ÄòThe Father of American Psychiatry‚Äô) was an initial supporter of patient-centric treatment of mental health conditions (Farr, 1944). The period encompassing the 17th and 18th centuries often represents a negative viewpoint of mental health, with patients committed to insane asylums, chained to their beds and not quizzed regarding their condition. Rush instead sought to engage with patients, as this would give a more detailed overview of their condition. Wilhelm Griseinger then built upon this further by introducing the concept of a ‚Äòpathophysiology‚Äô where mental disorders were the product of physiological changes in the body and brain. He also suggested that symptoms at different time points may in fact be caused by time-varying effects of the same condition (Marx, 1972). And finally, it was Emil Kraepelin who was the first to practically develop and introduce the concept of ‚Äòdiagnostic classification‚Äô (at least in the conventional categorical sense). This stems from his work with psychosis, to which his opinion differed from popular opinion at the time. Namely, Kraepelin did not believe that certain symptoms were characteristic for specific illnesses, rather that that specific combinations of symptoms and the time-course could be used to identify them instead (Ebert &amp; Bar, 2010). <br/> <br/></p> <h2 id="the-development-of-modern-classification-systems">The development of modern classification systems</h2> <p>It is important to understand the historical origins of psychiatry because they have directly influenced the modern systems that we use. For example, the Fifth Edition of the Diagnostic and Statistical Manual of Mental Disorders (DSM-V) is the primary diagnostic manual used in the diagnosis of mental disorders in North America. It is developed in an iterative process from earlier versions, which they themselves are influenced by earlier-still diagnostic manuals. For example, the Schneideran First Rank symptoms for schizophrenia developed by Kurt Schnieder in 1950, subsequently influenced Spitzer‚Äôs initial classification in the DSM-III three decades later (Kendler, 2009).</p> <p>There are additional limitations based in history. The developers of such classification systems were in a relative state of ignorance regarding the (as we now understand) incredibly complex etiology of mental health disorders. This was reflected in the ‚Äòessentialist view‚Äô a now-challenged framework, viewing mental health disorders are being caused by some shared essential criterion (Kendler, 2010; Adriens and De Block, 2013). In addition, there is the tendency to project a priori beliefs about the things they are classifying, and the nature and goals of those classifications (Kendler, 2009). <br/></p> <p>Current treatments for mental health disorders demonstrate a success rate far behind what is necessary to keep up with the concurrent increase in prevalence. This lack of efficacy is partly a consequence of the current methods used to classify, diagnose and treat mental health disorders, primarily diagnostic manuals such as the DSM and ICD, which have been the subject of scrutiny in recent years due to its repetitional nature (Forbes et al., 2023), low descriptive power of patient heterogeneity, and inability to map on to the underlying cognitive mechanisms. Subsequently, there are a number of alternative approaches, more strongly rooted in modern definitions of symptomatology. These include the Research Domain Criteria (RDoC, Insel et al., 2010), the Network Theory of Mental Disorders (Borsboom, 2017) and the Hierarchical Taxonomy of Psychopathology (Kotov, 2017). Each of these, whilst slightly different in their approach, aim to incorporate multiple ‚Äòlayers‚Äô of influence when considering the etiology and development on mental health conditions, and appreciates their transdiagnostic nature.</p> <p>The RDoC for example uses a core of five domains each capturing a distinct range of cognitive and behavioural processes, including: Negative Valence Systems (fear, anxiety, frustration), Positive Valence Systems (motivation, reward, pleasure), Cognitive Systems (Attention, perception, learning), Social Processes (Communication, interpersonal interactions, attachment) and Arousal and Regulatory Systems (Sleep, wakefulness, stress response).</p> <p>Within each of these domains, specific dimensions, called constructs, capture key aspects of functioning. For example, ‚Äúreward anticipation‚Äù is a construct within the Positive Valence Systems domain. These constructs are importantly assessed through various units of analysis at different levels, such as neuroimaging (systems), cognitive tests (behavioural), or self-report surveys (social).</p> <p>Somewhat similarly, The HiTOP framework, aims to re-classify mental health classification by introducing a hierarchical organization of symptoms and behaviours. It does this by organizing symptoms into increasingly broader ‚Äúspectra‚Äù. It also focuses on the idea of a continuous rather than discrete framework of classification. Instead of discrete categories like ‚Äúbipolar disorder,‚Äù HiTOP uses continuous dimensions like ‚Äúinternalizing distress‚Äù or ‚Äúexternalizing disinhibition‚Äù to describe an individual‚Äôs profile. This is reflected in its transdiagnostic approach, where it recognizes that symptoms often overlap across traditional diagnoses. This reflects how similar symptoms can have different underlying causes in different people, blurring the lines between categories. Finally, also similar to RDoC, HiTOP considers evidence from various levels, including genes, brain circuits, behaviors, and subjective experiences, to create a comprehensive picture of mental health.</p> <p>The network theory is different from the HiTOP and RDoC, in that it also proposes a statistical framework. It does this by virtue of proposing that mental disorders are best represented by complex webs of interacting symptoms, which constitute individual nodes in a network. Subsequently, various nodes and networks influence each other more or less based upon their properties as dictated by graph theory, such as distance and complexity. Consequently, complex networks encompassing both symptomatic and social influences can describe how certain symptoms and factors affect one another. <br/> <br/></p> <h2 id="conclusion">Conclusion</h2> <p>Mental health has always been a difficult concept to classify, due to the underlying complexity and heterogeneity across individuals. In addition, unlike conventional diseases which you can see, and perform a range of viable biological tests, mental disorders are not so easily tested, nor is there an universal objective measure in assessment. Understanding the historical origins of diagnostic classification is an important topic for neuroscientists interested in psychiatry to consider, as whilst we may be relatively educated to test scientific theories, we should also understand the nature of what we are ultimately looking to treat. Whilst the ICD and DSM are still the primary method of diagnosis, stemming from its practicality, from a scientific perspective, taking a complex approach is becoming more and more influential. Only by understanding mental health in all its complexity, can we subsequently develop effective treatments. <br/> <br/></p> <h2 id="references">References</h2> <p>Adriaens, P. R., &amp; De Block, A. (2013). Why we essentialize mental disorders. Journal of Medicine and Philosophy, 38(2), 107-127.</p> <p>Borsboom, D. (2017). A network theory of mental disorders. World psychiatry, 16(1), 5-13.</p> <p>Debernardi, A., Sala, E., D‚ÄôAliberti, G., Talamonti, G., Franchini, A. F., &amp; Collice, M. (2010). Alcmaeon of croton. Neurosurgery, 66(2), 247-252.</p> <p>Ebert, A., &amp; B√§r, K. J. (2010). Emil Kraepelin: A pioneer of scientific understanding of psychiatry and psychopharmacology. Indian journal of psychiatry, 52(2), 191-192.</p> <p>Farr, C. B. (1944). Benjamin Rush and American psychiatry. American Journal of Psychiatry, 100(6), 2-2.</p> <p>Forbes, M. K., Neo, B., Nezami, O. M., Fried, E. I., Faure, K., Michelsen, B., ‚Ä¶ &amp; Dras, M. (2023). Elemental psychopathology: Distilling constituent symptoms and patterns of repetition in the diagnostic criteria of the DSM-5.</p> <p>Frampton, M. F. (1991). Aristotle‚Äôs cardiocentric model of animal locomotion. Journal of the History of Biology, 291-330.</p> <p>Insel, T., Cuthbert, B., Garvey, M., Heinssen, R., Pine, D. S., Quinn, K., ‚Ä¶ &amp; Wang, P. (2010). Research domain criteria (RDoC): toward a new classification framework for research on mental disorders. American Journal of psychiatry, 167(7), 748-751.</p> <p>Kendler, K. S. (2009). An historical framework for psychiatric nosology. Psychological medicine, 39(12), 1935-1941.</p> <p>Kendler, K. S., Zachar, P., &amp; Craver, C. (2011). What kinds of things are psychiatric disorders?. Psychological medicine, 41(6), 1143-1150.</p> <p>Kotov, R., Krueger, R. F., Watson, D., Achenbach, T. M., Althoff, R. R., Bagby, R. M., ‚Ä¶ &amp; Zimmerman, M. (2017). The Hierarchical Taxonomy of Psychopathology (HiTOP): A dimensional alternative to traditional nosologies. Journal of abnormal psychology, 126(4), 454.</p> <p>Marx, O. M. (1972). Wilhelm Griesinger and the history of psychiatry: a reassessment. Bulletin of the History of Medicine, 46(6), 519-544.</p>]]></content><author><name></name></author><category term="articles"/><category term="psychiatry,"/><category term="psychology,"/><category term="computational"/><category term="modeling,"/><category term="philosophy"/><summary type="html"><![CDATA[A quick review of classification methods in psychiatry]]></summary></entry><entry><title type="html">How to program efficiently using ChatGPT for psychology and neuroscience research</title><link href="https://sohaamir.github.io/blog/2023/chatgpt_and_psychology/" rel="alternate" type="text/html" title="How to program efficiently using ChatGPT for psychology and neuroscience research"/><published>2023-10-07T13:56:00+00:00</published><updated>2023-10-07T13:56:00+00:00</updated><id>https://sohaamir.github.io/blog/2023/chatgpt_and_psychology</id><content type="html" xml:base="https://sohaamir.github.io/blog/2023/chatgpt_and_psychology/"><![CDATA[<p><em>ChatGPT has exploded onto the social and academic sphere of influence. Amongst its many uses within academia is the ability to generate and analyse blocks of code in response to a user prompt. Such a transition from human-based feedback (e.g., GitHub, Stack Overflow) to AI-based feedback for code generation and correction has emphasized the need to provide efficient prompts. Levying anecdotal experience with generating code using ChatGPT in my own research, I briefly discuss simple rules for designing prompts in the field of psychology and neuroscience.</em></p> <h1 id="introduction">Introduction</h1> <p>The introduction of ChatGPT (GPT-3 in 2022 followed by GPT-4 in 2023) to the public sphere has left an immediate impact upon modern society in a short period of time, with the platform reaching one million users far quicker than any service prior. Due to the flexibility and variability in its use, ChatGPT has been integrated into many job sectors, including academia. However, this has come as both a benefit and a bane towards academic research and teaching. Whilst students and academics can undoubtedly benefit from its role as a publicly available academic tutor, available at any time to provide shortened and simplified explanations of complex topics, the very same feature can also provide templated answers for marked examinations, altering the very nature of academic learning and grading (Anders, 2023; Cotton et al., 2023; Rudolph et al., 2023). Simultaneously, it‚Äôs pervasive use as a source of information and ability to provide feedback towards elements of experimental design and analyses (e.g., power calculations) has raised the question of whether ChatGPT should be credited as an academic author, forcing a stance on this topic to be given from major publishing journals (Curtis, 2023; Liebrenz et al., 2023; Nature Editorials, 2023). <br/></p> <div style="text-align: center;"> <img src="/assets/img/posts/chatgpt_research/chagpt_popularity.png" alt="ChatGPT Popularity" width="600" height="225"/> </div> <p><br/> <strong>Interest in ChatGPT over time.</strong> <em>Figure taken from a Google Trend search for ‚ÄòChatGPT‚Äô within the last 12 months (Search conducted on the 26th of August 2023). Numbers represent search interest relative to the highest point on the chart for the given region and time. A value of 100 is the peak popularity for the term. A value of 50 means that the term is half as popular. A score of 0 means there was not enough data for this term.</em> <br/></p> <div style="text-align: center;"> <img src="/assets/img/posts/chatgpt_research/chatgpt_bar_chart.png" alt="ChatGPT Bar Chart" width="600" height="360"/> </div> <p><br/> <strong>Time for major online services to reach 1 million users.</strong> <em>Figure adapted by A.S. from an online version https://www.tooltester.com/en/blog/chatgpt-statistics/. Whilst Threads (a Twitter/X influenced platform from Meta) has since reached this milestone quicker than ChatGPT, it did so benefitting from an already prevalent user-base and brand.</em> <br/> <br/> A major influence on academic research is the ability of ChatGPT to provide workable code in response to a given prompt, and to debug faulty code given both the code and the associated error message, significantly improving programming efficiency. This is a consequence of the fundamental building block of ChatGPT, natural language processing (NLP), which enables the artificial intelligence (AI) algorithm to understand and process human language. Through a combination of machine learning algorithms and vast amounts of training data, the model learns patterns and relationships between words, phrases, and sentences, probabilistically selecting the next word within a generated response, time and time again. This same principle extends to programming languages by virtue of how both human and programming languages consist of their own syntax, grammar, and semantics. As ChatGPT recognises English, Italian, French and other cultural languages, it can generate blocks of code for a variety of programming languages including those most relevant to academics in the field of Psychology such as HTML, CSS, JavaScript, Julia, Python, and R. Such blocks of code are produced at a rate far beyond the capacity for human programmers. Whilst the working capacity of GPT-4 slows this production of code in comparison to GPT-3.5, sections of code are nevertheless generated in the order of seconds. Such a ‚Äòreal-time Stack Overflow‚Äô is a significant tool in the arsenal of any academic, particularly beginners in the field of psychology for which an unfamiliarity with programming severely lengthens facets of data analysis or experimental design requiring programming experience. Being in this category, I found ChatGPT to be extremely beneficial, both improving productivity whilst also increasing my conceptual knowledge in the subject, as ChatGPT also provides additional information regarding the specific functions of the code when producing it. <br/> <br/> However, whilst ChatGPT can provide meaningful code, it is not without fault. Indeed, whilst heralded as an academic ‚Äòpanacea‚Äô (Quintans-J√∫nior et al., 2023) it also provides unusual errors in response to basic prompts. An overview of such errors (Borji, 2023), designates twelve categories, including ‚ÄòReasoning‚Äô, ‚ÄòLogic‚Äô, ‚ÄòMath and Arithmetic‚Äô and indeed ‚ÄòCoding‚Äô. Examples of this latter category can stem from two sources, either from a limitation associated with the machinery to which ChatGPT provides code from any given prompt, or a limitation of the prompt given to ChatGPT from the user. <br/></p> <div style="text-align: center;"> <img src="/assets/img/posts/chatgpt_research/errors.png" alt="ChatGPT Errors" width="700" height="350"/> </div> <p><br/> <br/> <strong><em>Sources of user and model-related error in ChatGPT code generation.</em></strong> <em>User-related errors such as not including relevant information in the prompt can lead to faults suspected to be the cause of the model but can be circumvented by changing the prompt. On the other hand, model-related errors are a direct cause of the model itself. In the first example on the left, the second line of code is entirely unnecessary, whilst the error below reflects the common scenario where ChatGPT provides faulty code. The latter can subsequently be corrected by inputting the error back into ChatGPT. Examples of ‚Äòhallucinations‚Äô on the right provide examples where faulty logic gives an incorrect response. In these examples, ChatGPT fails to provide the correct answer to the first question, answering Elvis Presley (the correct answer is Elvis Perkins), fails to label 17077 as being a prime number and fails to provide the correct answer for the number of socks (40). It should be noted that ChatGPT is constantly improving its accuracy in this domain, see (Chen et al., 2023) for changing responses to the second example. The example for the first question is taken from (OpenAI, 2023), third from (Plevris et al., 2023).</em> <br/> <br/> Ultimately, an examination of GPT‚Äôs replies to 517 questions from Stack Overflow, revealed that 52% of ChatGPT‚Äôs answers contain inaccuracies and 77% are verbose. In addition, ChatGPT‚Äôs answers were found on the whole to be more incorrect, significantly lengthy, and not consistent with human answers half of the time (Kabir et al., 2023). The authors posit that this stems from ChatGPT‚Äôs incapability to understand the underlying context of the question being asked, as it was found to rarely make syntax errors for code answers. Such errors can be avoided by providing meaningful, tailored prompts to begin with. Of course if such faulty or inaccurate code is generated, this code can be inputted back into ChatGPT ad infinitum to eventually reach a solution, but such recursive programming can be unnecessary if the initial prompt given is of adequacy. The subject of this short paper is therefore to focus on providing efficient prompts through three simple rules, resulting in a more efficient workflow. Whilst I will be using real-world examples from my own experience as an academic in the field of psychology, these rules are also transferable to other scientific disciplines. <br/> <br/></p> <h1 id="detail-in-detail-out">Detail In, Detail Out</h1> <p>Despite ChatGPT‚Äôs ability to produce responses from basic prompts, its response is naturally limited by the information provided by the user. As noted in a recent discussion of ChatGPT‚Äôs potential as a programming support tool, this ‚Äúdepends on the user‚Äôs skill in giving instructions. The AI will not respond appropriately if user instructions are long, vague, or have lack of context‚Äù (Avila-Chauvet et al., 2023). Modifying the adage of ‚ÄòGarbage In, Garbage Out‚Äô, programming with GPT often reflects ‚ÄòDetail In, Detail Out‚Äô. Take the following example in which I had asked for a series of plots to be generated from some data that I had directly inputted into ChatGPT. Whilst the data itself was recognised; I had neglected to provide information regarding the filename. As such, ChatGPT defaulted to ‚Äòdata.csv‚Äô as the input. On another example, it defaulted to ‚Äúyour_file_path.csv‚Äù. This is a simplistic overview of a tendency to generalise, to which ChatGPT will default if not instructed otherwise. Relatedly, ChatGPT has also inferred from unspecific prompts, to produce the relevant code in Python, when R was preferred. <br/> <br/> The same principle also applies when debugging errors using feedback from ChatGPT. Solely providing the error message generated, in addition to the code can result in a solution, but a solution can be tailored to your specific problem by providing the actual structure of the data being acted upon. For example, specific data checks can be inferred where the data were previously inputted into ChatGPT. Such prompts are indeed possible without providing the data, but as prompted by the AI model itself, the more information that is provided, the more relevant the outputted code will be. And finally, the level of detail impacts how data is visualized. Akin to two artists, one asked simply to draw a face, versus another asked to draw a face of a happy 60-year old man, wearing glasses, with grey hair and a beard, the input given to ChatGPT significantly matters with providing relevant code in line with one‚Äôs request. Take the simple prompt below: <br/> <br/> <strong><em>Prompt:</em></strong> <br/> <em>Generate a graph in R, plotting height versus weight in a group of 20 males.</em> <br/> <br/> To which the resulting code produces the following graph: <br/></p> <div style="text-align: center;"> <img src="/assets/img/posts/chatgpt_research/height_1.png" alt="Height 1" width="600" height="300"/> </div> <p><br/> However, making a simple modification to the prompt can significantly affect how the data is presented. For example, adding the pretence to make the graph ‚Äúsuitable for a scientific publication‚Äù yields the following graph: <br/></p> <div style="text-align: center;"> <img src="/assets/img/posts/chatgpt_research/height_2.png" alt="Height 2" width="600" height="300"/> </div> <p><br/> Note the addition of several components, including adding a colour scheme to individual data points, a more detailed plot title, and a legend. Such a feature again builds upon the AI‚Äôs understanding on what a graph for a scientific publication generally constitutes, and so it should be used with additional specific prompts when generating graphs for this specific purpose. <br/> <br/> Another example is given where I prompted the creation of a single column csv file with the following instructions: <br/> <br/> <em>Generate a single-column csv file which has random values from 0-100 in each of the following rows: 1, 2, 4, 5, 8, 9, 11, 12, 15, 16, such that there is a gap of one between the first two pairs and a gap of two with the second two pairs. Continue to do this until the 348th row, which should also contain a number. Importantly, I would like for each pair of numbers to be the same. So, with the example above, 1 and 2 will be the same number, 4 and 5 the same, 8 and 9 the same and so on. Save this to a file called ‚Äòsingle_sub_scores.csv‚Äô.</em> <br/> <br/> Whilst I specifically mentioned that there should be a gap between those rows mentioned, the output generated instead did not have any gaps. <br/></p> <div style="text-align: center;"> <img src="/assets/img/posts/chatgpt_research/data_column_one.png" alt="Column One" width="60" height="250"/> </div> <p><br/> Subsequently, I provided an example directly into ChatGPT which contained the exact structure required, and even despite this, and the confidence in the response: <br/> <br/> <em>Ah, I see what you‚Äôre asking for now. Here‚Äôs a modified version of the R script that includes a gap (NA) after every second pair of numbers:</em> <br/> <br/> The output was still incorrect. The following prompt generated a structure very similar (but not quite correct) to what was intended: <br/> <br/> <em>That‚Äôs not correct, the structure of your outputted csv does not match the structure of the column which I provided. There should be a single gap between the first two columns, and then a gap of two, followed by a gap of one, etc.</em> <br/></p> <div style="text-align: center;"> <img src="/assets/img/posts/chatgpt_research/data_column_two.png" alt="Column Two" width="60" height="250"/> </div> <p><br/> After both the example column and the column generated above were both inputted back into ChatGPT, it still was unable to create the required column. I then repeated this once more. Even though it would understand the intended pattern: <br/> <br/> <em>The pattern should indeed be two numbers, one empty row, two numbers, two empty rows, and so on.</em> <br/> <br/> It still repeatedly provided the wrong code a few more times, before finally providing the correct code. <br/></p> <div style="text-align: center;"> <img src="/assets/img/posts/chatgpt_research/data_column_three.png" alt="Column Three" width="60" height="250"/> </div> <p><br/> This process, whilst significantly quicker than writing the code from scratch (for a programming novice I should mention), still took around 10-15 minutes to create. But how could one generate the correct code from a single prompt, and avoid repeatedly correcting ChatGPT? Well, simply asking ChatGPT for such a prompt provided the following: <br/> <br/> <em>‚ÄúGenerate a R script that creates a csv file named ‚Äòsingle_sub_scores.csv‚Äô with a single column of 348 rows. The rows should follow this pattern: two rows containing the same random number from 0 to 100, one empty row, two rows with another random number, two empty rows, and so on. The pattern should keep alternating between one and two empty rows. Empty rows should be represented as NA in R but should appear as empty cells in the resulting csv file when opened in Excel.‚Äù</em> <br/> <br/> Interestingly, the code generated significantly differs from the correct code provided earlier, with the inclusion of a function to generate the number sequences. Below, the original code is on the right, with the code generated from the prompt above on the left. <br/></p> <div style="text-align: center;"> <img src="/assets/img/posts/chatgpt_research/r_code.png" alt="R Code" width="700" height="300"/> </div> <p><br/> But the correct output was generated, albeit not as integers. <br/> <br/> In general therefore, one should provide the AI model with as much information as possible in the prompt. This is both to prevent generalisations in the case of ambiguity, and to increase the specificity of the code generated. Indeed, when asking ChatGPT if it would prefer to have such additional information regarding an issue it acknowledges the benefits of having specific information. <br/> <br/> <strong>Prompt</strong> <br/> <br/> <em>Let me know if you need information regarding the structure and/or contents of either item.location or MRS.</em> <br/> <br/> <strong>ChatGPT</strong> <br/> <br/> <em>Yes, that would be helpful. Please provide the structure and contents (at least some sample data if it‚Äôs too large) of item.location and MRS variables. Also, if you can provide information about the expected operation, i.e., what the projection operation should result in, that would be very helpful in finding a solution.</em> <br/> <br/> Such detail may indeed span multiple prompts (see below), however the benefits observed outweigh the additional effort. Ultimately, the following structure/questions may be useful when planning one‚Äôs own prompts: <br/></p> <ul> <li><strong>Background for the prompt‚Äôs motivation</strong> <ul> <li>Pre-text: Set the scene regarding your data. Describe your experimental design, methodologies, and statistical design (including programming language).</li> <li>Data: Describe the data. What data are you working/expecting to work with (i.e., neural, behavioural? What is the structure of the data?</li> </ul> </li> <li><strong>The prompt</strong> <ul> <li>Prompt Outputs: What should be generated from the prompt? Including additional details (e.g., filename, specificity of syntax) can result in a more tailored output.</li> </ul> </li> <li><strong>Feedback</strong> <ul> <li>Was the output generated in line with my needs? Provide specific feedback in the circumstance of AI-generated error or inaccuracy.</li> </ul> </li> </ul> <p><br/></p> <h1 id="rule-2--building-complex-scripts">Rule 2 ‚Äì Building complex scripts</h1> <p>Given the length and complexity of certain scripts, it may simply be unfeasible to provide a single minutely detailed prompt. Even though ChatGPT would eventually churn out the code in its entirety, a mistake would be propagated throughout, and any rectification would necessitate running the entire code from scratch, a time-consuming endeavour. Instead, separating code in chunks, and optimising each chunk in succession may be a useful strategy. Another example relates to the creation of a more complex script, where multiple relationships between parameters may be required. Such complex scripts can be difficult to initially visualise as a prompt but may instead be iteratively developed by setting a ‚Äòbasic environment‚Äô and subsequently adding layers of complexity. Take the following example where a simulated dataset was created for a metacognitive decision-making task, in which I aim to ultimately distinguish between behavior and choice amongst those with high and low trait-metacognition. In the first prompt, I set the basic overview of the task: <br/> <br/> <em>I have a hypothetical task, in which participants start with 100 points in the bank. The objective of the task is to gain as many points as they can. The task is a visual discrimination task, which is split into a number of blocks. Each block will be titrated to have the participant‚Äôs performance at a certain level. For example, block one will be titrated to have a score of 60% whilst block 2 will have 70%, block 3 at 50% etc.</em> <br/> <br/> <em>The values of the performance titration are not important however, just that it changes throughout the task. At the start of each block, we will measure the participants confidence, from a scale of 1-10. They will then have the option of placing a wager, which will again, be on a scale from 1-10 points. They will then complete the block, which will be titrated to a particular performance level. Finally, at the end of the block, they will be asked whether they would like to change their initial bet, which they can place from a scale of 1-10. We will run a total of 10 blocks. With this task in mind, please create a simulated dataset for a group of 30 participants.</em> <br/> <br/> The created dataset did not contain all my intended variables, and so I added more in the next two iterations: <br/> <br/> <em>I would now like to make some modifications to the task design. Before the pre_block_confidence for each block, I would like a measurement of how many points the person thinks they will gain or lose by the end of the block (pre_block_score_estimation). This will be on a scale from -10 to + 10. After each block, we will again measure confidence, but ‚Äòpost_block_confidence‚Äô contrasting with the already mentioned ‚Äòpre_block_confidence‚Äô. They will be measured in the same way, in a scale from 1-10. I will also measure their score estimation (post_block_score_estimation) at the end of each block, which will be before the post_block_confidence. I also would like to have some simulated scores at the end of each block, which follows the rules of the game, in that they can lose or gain a maximum of 10 points per trial, with 10 trials per block and 10 blocks in total.</em> <br/> <br/> <em>Now incorporate some additional relationships between confidence, wager, revised bet and estimated score, based upon differences one would see within a sample. For example, create data for 15 participants who are high-risk and have low metacognition, and 15 who are safe-betting and have high metacognition.</em> <br/> <br/> Importantly, ChatGPT pulls upon its vast knowledge base to project assumptions regarding the task onto the two hypothesized groups: <br/> <br/> Sure, to simulate the behavior of two groups of participants, we‚Äôll have to introduce more rules into the simulation. Here are some assumptions that I‚Äôll make to differentiate between the groups:</p> <ol> <li>High-risk participants with low metacognition: <ul> <li>Are more likely to make high wagers (8-10).</li> <li>Have a wider range of pre and post-block score estimations (-10 to +10).</li> <li>Are less accurate in their score estimations (deviation from actual block scores will be higher).</li> <li>Show no significant change in their wagers after completing the block (low metacognition).</li> </ul> </li> <li>Safe-betting participants with high metacognition: <ul> <li>Are more likely to make low wagers (1-3).</li> <li>Have a narrower range of pre and post-block score estimations (-3 to +3).</li> <li>Are more accurate in their score estimations (deviation from actual block scores will be lower).</li> <li>Show significant reduction in their wagers after a loss and increase after a win (high metacognition).</li> </ul> </li> </ol> <p>However, it is important that if simulating data featuring populations with specific facets of behaviour, that this behaviour is reflected in line with your a priori hypotheses. One such hypothesis in this instance related to the wagering post and pre-blocks, something not automatically inferred by ChatGPT, and so it was added in a subsequent prompt. <br/> <br/> <em>Adjust the behaviour of both groups such that those with higher metacognition are more likely to lower their post_block_wager compared to their pre_bet_wager if it is more difficult, and more likely to raise it, if it is easier. There will not be the case for those with low metacognition.</em> <br/> <br/> Ultimately, by chaining multiple prompts, I was successfully able to simulate a relatively complex dataset, which fit the purpose of simulating potential results of the study as part of a presentation to funders. Whilst single, lengthy prompts can be provided to build a stronger ‚Äòbase‚Äô to develop on, an iterative process is inevitable when creating complex scripts. <br/> <br/></p> <h1 id="rule-3--gpt-4-vs-gpt-35">Rule 3 ‚Äì GPT-4 vs GPT-3.5</h1> <p><br/> On March 14th 2023, OpenAI released GPT-4, the successor to GPT-3.5. Whilst the two models share a lot of common features, GPT-4 features a significantly larger architectural model size than its predecessors, including GPT-3. This increased model size ‚Äúhelps improve its natural language processing capabilities, resulting in more accurate and relevant responses‚Äù (Koubaa, 2023). However, conversely to previous versions, the specifics behind GPT-4‚Äôs architecture were not revealed to the community. Indeed, in their technical report for GPT-4, OpenAI explicitly state that: ‚ÄúGiven both the competitive landscape and the safety implications of large-scale models like GPT-4, this report contains no further details about the architecture (including model size), hardware, training compute, dataset construction, training method, or similar‚Äù (OpenAI, 2023). <br/> <br/> What is known from the technical report is that GPT-4 outperforms GPT-3.5 in a variety of academic and professional assessments, particularly so in the: <br/></p> <ul> <li>Uniform Bar Exam (90th percentile compared to the 10th percentile)</li> <li>LSAT (88th percentile compared to the 40th)</li> <li>SAT Math (89th percentile compared to the 70th)</li> <li>GRE Quantitative/Verbal (80th/99th percentile compared to the 25th/63rd)</li> </ul> <p>Included among these tests were a series of coding problems provided through LeetCode (an online platform that provides a collection of coding challenges) in which GPT-4 performed better than GPT-3.5 in all levels of difficulty, including:</p> <ul> <li>easy (31/41 problems solved compared to 12),</li> <li>medium (21/80 compared to 8), and</li> <li>hard (3/45 compared to 0).</li> </ul> <p>Given this clear improvement in performance, is there a benefit in using GPT-4 versus GPT-3.5 when programming in academia? From my experience, there is certainly an observable difference in the quality of the code generated. Take the earlier example where the following prompt was generated by ChatGPT to generate a specific pattern of numbers: <br/> <br/> <strong>Prompt:</strong> <br/> <br/> <em>‚ÄúGenerate a R script that creates a csv file named ‚Äòsingle_sub_scores.csv‚Äô with a single column of 348 rows. The rows should follow this pattern: two rows containing the same random number from 0 to 100, one empty row, two rows with another random number, two empty rows, and so on. The pattern should keep alternating between one and two empty rows. Empty rows should be represented as NA in R but should appear as empty cells in the resulting csv file when opened in Excel.‚Äù</em> <br/> <br/> <strong><em>GPT-3.5 vs GPT-4 ‚Äì End result of generated code</em></strong> <br/></p> <div style="text-align: center;"> <img src="/assets/img/posts/chatgpt_research/data_columns_four_and_five.png" alt="More R Columns" width="500" height="500"/> </div> <p><br/> Interestingly whilst neither are correct, only GPT-4 creates the correct pattern. However, there are certain examples in which GPT-4 demonstrates a clear advantage over GPT-3.5. Take the following prompt, again involving the subsetting of data: <br/> <br/> <em>I have the dataframe ‚Äòfinal_data_filtered‚Äô in R, which has the following structure:(data structure provided)</em> <br/> <br/> <em>I would like for you, for each Participant.Private.ID in rows where the column ‚ÄòMeasure‚Äô is ‚Äòrating‚Äô, to plot ‚ÄòResponse.pleasure‚Äô - ‚ÄòResponse.nutrition‚Äô against ‚ÄòResponse.value‚Äô. I would like for this to be plotted across the whole group (i.e., for all ‚ÄòParticipant.Private.ID‚Äô but also to plot the mean ‚ÄòResponse.pleasure‚Äô - ‚ÄòResponse.nutrition‚Äô against the mean ‚ÄòResponse.value‚Äô for each ‚ÄòParticipant.Private.ID‚Äô.</em> <br/> <br/> <em>Save the output as data frames so I can inspect them.</em> <br/> <br/> This is the corresponding data frame and plots for GPT-3.5 and GPT-4: <br/></p> <div style="text-align: center;"> <img src="/assets/img/posts/chatgpt_research/four_r_graphs.png" alt="R plots" width="700" height="700"/> </div> <p><br/> Note that whilst the individual level plots are the same (with GPT-3.5‚Äôs output even separating the different participants) only GPT-4 correctly creates the mean graphs for each participant, as seen in the graph on the right. <br/> <br/> Inaccuracies also are visible when simply relying on the processing of the LLM itself. When asked to provide a list of unique items within two sets of 420 items (with each 60 unique items repeated 7 times in succession), GPT-4 incorrectly states that there were 46 unique items in list 1, and 44 unique items in list 2, when in fact there were 60 unique items in both list. In addition, when asked to list items present in both lists, it only lists 12, when there are in fact 20 (something it can accurately determine using programming). <br/></p> <div style="text-align: center;"> <img src="/assets/img/posts/chatgpt_research/more_columns.png" alt="More R columns" width="600" height="330"/> </div> <p><br/> Another important factor concerning GPT-4 is that it is currently only available through a subscription to ChatGPT Plus, a $20 (or equivalent) monthly subscription where the user also gains unlimited access to GPT-3.5 (it is not available to unsubscribed users during peak usage). The question remains as whether GPT-4 is worth the price. In my opinion, GPT-3.5 does significantly well for more basic coding needs, and whilst GPT-4 is more accurate for more complex programming tasks, both versions have the same underlying flaws with logic and inference. When asked itself to provide some examples of these limitations, six were given, of which four were relevant for psychologists and/or neuroscientists, and in line with this paper‚Äôs message. <br/> <br/> <strong><em>Execution of Code:</em></strong> I can help generate code snippets based on the information provided, but I don‚Äôt have the ability to execute code or provide real-time debugging. This means <em>I can‚Äôt run your code, see what the output is, and make adjustments accordingly.</em></p> <p><strong><em>Real-time collaboration or pair programming:</em></strong> My responses are stateless, which means I don‚Äôt have the ability to remember past interactions. This can make back-and-forth collaboration more challenging, as <em>I won‚Äôt recall what was discussed or decided in earlier conversations.</em></p> <p><strong><em>Very complex, context-dependent tasks:</em></strong> While I can help with many coding tasks, <em>very complex tasks that require deep understanding of a specific project‚Äôs context or intricate knowledge of a codebase could be challenging for me.</em></p> <p><strong><em>Writing large, complex programs:</em></strong> While I can help with small code snippets and even functions or modules, <em>writing an entire complex software application with numerous interconnected parts is beyond my scope.</em> <br/> <br/></p> <h1 id="conclusion">Conclusion</h1> <p><br/> Programming is a necessary facet of academic research. The release of ChatGPT, with its ability to generate commented code in real-time in response to user-inputted prompts has in part shifted the necessity to learn the specific of coding, towards knowing how to provide efficient prompts to provide optimal code. Efficiency in this space is reflected by providing relevant information, asking the right questions, and choosing the right model. Doing so can reduce the primary limitations of inference and generalisation of ChatGPT when generating its response, a significant contribution towards incorrect code (Kabir et al., 2023). <br/> <br/></p> <h1 id="references">References</h1> <p>Anders, B. A. (2023). Is using ChatGPT cheating, plagiarism, both, neither, or forward thinking?. Patterns, 4(3).</p> <p>Avila-Chauvet, L., Mej√≠a, D., &amp; Acosta Quiroz, C. O. (2023). Chatgpt as a support tool for online behavioral task programming. Available at SSRN 4329020.</p> <p>Borji, A. (2023). A categorical archive of chatgpt failures. arXiv preprint arXiv:2302.03494.</p> <p>Chen, L., Zaharia, M., &amp; Zou, J. (2023). How is ChatGPT‚Äôs behavior changing over time?. arXiv preprint arXiv:2307.09009.</p> <p>Cotton, D. R., Cotton, P. A., &amp; Shipway, J. R. (2023). Chatting and cheating: Ensuring academic integrity in the era of ChatGPT. Innovations in Education and Teaching International, 1-12.</p> <p>Curtis, N. (2023). To ChatGPT or not to ChatGPT? The impact of artificial intelligence on academic publishing. The Pediatric Infectious Disease Journal, 42(4), 275.</p> <p>Editorials, N. (2023). Tools such as ChatGPT threaten transparent science; here are our ground rules for their use. Nature, 613(612), 10-1038.</p> <p>Kabir, S., Udo-Imeh, D. N., Kou, B., &amp; Zhang, T. (2023). Who Answers It Better? An In-Depth Analysis of ChatGPT and Stack Overflow Answers to Software Engineering Questions. arXiv preprint arXiv:2308.02312.</p> <p>Koubaa, A. (2023). GPT-4 vs. GPT-3.5: A concise showdown.</p> <p>Liebrenz, M., Schleifer, R., Buadze, A., Bhugra, D., &amp; Smith, A. (2023). Generating scholarly content with ChatGPT: ethical challenges for medical publishing. The Lancet Digital Health, 5(3), e105-e106.</p> <p>OpenAI. (2023). GPT-4 Technical Report. https://cdn.openai.com/papers/gpt-4.pdf</p> <p>Plevris, V., Papazafeiropoulos, G., &amp; Rios, A. J. (2023). Chatbots put to the test in math and logic problems: A preliminary comparison and assessment of ChatGPT-3.5, ChatGPT-4, and Google Bard. arXiv preprint arXiv:2305.18618.</p> <p>Quintans-J√∫nior, L. J., Gurgel, R. Q., Ara√∫jo, A. A. D. S., Correia, D., &amp; Martins-Filho, P. R. (2023). ChatGPT: the new panacea of the academic world. Revista da Sociedade Brasileira de Medicina Tropical, 56, e0060-2023.</p> <p>Rudolph, J., Tan, S., &amp; Tan, S. (2023). ChatGPT: Bullshit spewer or the end of traditional assessments in higher education?. Journal of Applied Learning and Teaching, 6(1).</p>]]></content><author><name></name></author><category term="articles"/><category term="machine"/><category term="learning,"/><category term="artifical"/><category term="intellligence,"/><category term="academia"/><summary type="html"><![CDATA[An article covering my experience and tips for using ChatGPT to aid programming]]></summary></entry><entry><title type="html">Setting up an academic website - a guide for absolute beginners</title><link href="https://sohaamir.github.io/blog/2023/setting_up_website/" rel="alternate" type="text/html" title="Setting up an academic website - a guide for absolute beginners"/><published>2023-10-01T13:56:00+00:00</published><updated>2023-10-01T13:56:00+00:00</updated><id>https://sohaamir.github.io/blog/2023/setting_up_website</id><content type="html" xml:base="https://sohaamir.github.io/blog/2023/setting_up_website/"><![CDATA[<p><em>Let‚Äôs say you just started a new position (maybe as a PhD student) and would like to create an academic website, as seems to be all the rage nowadays. However, are relatively new to programming, and are unsure on where to even get started. Creating a website can seem to be a daunting task, but the initial steps to creating a basic website is actually quite simple (even a numbskull like myself can do it!). This post will cover all of the steps that you need in order to create the base for an academic website using the academicpages template.</em> <br/></p> <div style="text-align: center;"> <img src="/assets/img/posts/website_guide/typing.gif" alt="Typing GIF" width="500" height="250"/> <p style="text-align: center;"><em>Not all programmers work like this.</em></p> </div> <h1 id="choosing-which-website-template-works-for-you">Choosing which website template works for you</h1> <p>The first question that you should ask yourself is which template you would like to use. Two of the most popular options, at least when creating an ‚Äòacademic‚Äô website are the <a href="https://academicpages.github.io/">academicpages</a> template in Jekyll, or the <a href="https://academic-demo.netlify.app/">Academic Theme</a> in Hugo. If the words ‚ÄòJekyll‚Äô and ‚ÄòHugo‚Äô mean nothing (apart from a vague recollection of 19th century literature) then that‚Äôs ok! All you need to know is that the two look slightly different in their presentation, and that the set-up and maintenance of each website (in terms of programming) will be quite different. Both are very popular and so have plenty of guides and help available, however it is worth looking at each of the two before choosing which theme you would like.</p> <p>(Of course, selecting these two themes stem from my personal preference in having a more ‚Äòconventional‚Äô theme, there are plenty of other alternatives to choose from!)</p> <div style="display: flex; justify-content: center; align-items: center;"> <figure> <img src="/assets/img/posts/website_guide/hugo_main_page.png" alt="Hugo Page" width="400" height="225" style="margin-right: 20px;"/> <figcaption style="text-align: center;">The Hugo Academic theme</figcaption> </figure> <figure> <img src="/assets/img/posts/website_guide/jekyll_main_page.png" alt="Jekyll Page" width="400" height="225" style="margin-left: 20px;"/> <figcaption style="text-align: center;">The academicpages theme</figcaption> </figure> </div> <p>I ended up choosing the academicpages (Jekyll) theme, because I preferred the aesthetic, the set-up is relatively easier, and I think with Hugo the default is to have all website content on the same page, scrolling down to see additional ‚Äòpages‚Äô, whereas on the Jekyll template, pages are actual pages (I may be wrong, and you can certainly change this). So if you also end up going for the academicpages template, read on for a guide in how to set-up your own website!</p> <p>Before we get started, there are a number of great tutorials that you can use in tandem (and which my own borrows from), I would highly recommend checking them out as well!</p> <ul> <li><a href="https://jayrobwilliams.com/posts/2020/06/academic-website/">Building an Academic Website</a> by Rob Williams</li> <li><a href="https://www.youtube.com/watch?v=8lJhXJCUYCc&amp;t=79s">Easiest Way to Create the Perfect Academic Website</a> by Boris Meinhardus. Great video tutorial!</li> <li><a href="https://www.cross-validated.com/Personal-website-with-Minimal-Mistakes-Jekyll-Theme-HOWTO-Part-II/">Personal Website with Minimal Mistakes Jekyll Theme HOWTO</a> by Katerina Bosko. Useful for making little changes later on.</li> <li><a href="https://yutongj.github.io/how-to-build-a-website/How-to-personalize-your-website/">Customize your personal website</a> by Yutong Jin.</li> </ul> <p><br/></p> <h1 id="getting-started-with-github">Getting started with GitHub</h1> <p>The base structure for the academicpages website is hosted on GitHub which you can get to using the <a href="https://github.com/academicpages/academicpages.github.io">following link</a>. I assume that you will know whtat GitHub is, but if you don‚Äôt it‚Äôs basically a site where people host code. I would highly recommend making an account, not least because you‚Äôll need one to go any further in this tutorial! There are instructions on what to do on their GitHub page, but you need to fork the repository (clone the files) to your own profile. This means that any changes that you make will be on your own ‚Äòversion‚Äô and not the original.</p> <div style="text-align: center;"> <img src="/assets/img/posts/website_guide/github_fork.png" alt="GitHub fork" width="600" height="200"/> </div> <p><br/> So then you‚Äôll have you own local version of the website to work with. You then need to access this version on your own machine. I did this using <a href="https://desktop.github.com/">GitHub Desktop</a>, which connects to your GitHub account and allows you to open your chosen repository in whatever text editor that you like to use. I use <a href="https://code.visualstudio.com/">VS Code</a>, so I chose that. When you open the repository, it should look something like this:</p> <div style="text-align: center;"> <img src="/assets/img/posts/website_guide/github_repo.png" alt="GitHub repo" width="600" height="350"/> </div> <p><br/> This may look quite scary to start with, but you only need to make a few changes to create a basic website. On the left, you have the repository, and the middle will be whichever file you have open.</p> <h1 id="checking-changes-locally-with-bundler">Checking changes locally with Bundler</h1> <p>Technically you won‚Äôt need this until after you make changes, but it‚Äôs typically a good thing to get everything that you need installed and working beforehand. When you make changes to your website, you would like to have a ‚Äòpreview‚Äô of what the changes look like, before you ‚Äòcommit‚Äô them to your repository. It saves a lot of time and effort rather than commiting the changes each time. To do this, we need something called Bundler. <a href="https://bundler.io/">Bundler</a> is a package manager for Ruby, which is the programming language that Jekyll is written in. You can check if you have Ruby installed by running</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ruby <span class="nt">-v</span>
</code></pre></div></div> <p>And if you do not, install ruby using <a href="https://brew.sh/">Homebrew</a> by</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>brew <span class="nb">install </span>ruby
</code></pre></div></div> <p>This may not happen to you, but when I did this, I got a permissions error:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ERROR:  While executing gem ... <span class="o">(</span>Gem::FilePermissionError<span class="o">)</span>
    You don<span class="s1">'t have write permissions for the /Library/Ruby/Gems/2.6.0 directory.
</span></code></pre></div></div> <p>Which I fixed by creating a <code class="language-plaintext highlighter-rouge">.bundle</code> directory in the root of my website‚Äôs repository (e.g., for me <code class="language-plaintext highlighter-rouge">~/Documents/GitHub/sohaamir.github.io/</code>).</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">mkdir</span> <span class="nt">-p</span> .bundle
<span class="nb">touch</span> .bundle/config
nano .bundle/config
</code></pre></div></div> <p>and then adding the following to the text file (Ctrl + O to save, Ctrl + X to exit):</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>BUNDLE_PATH: <span class="s2">"vendor/bundle"</span>
BUNDLE_BIN: <span class="s2">"vendor/bundle/bin"</span>
</code></pre></div></div> <p>You can then install bundle‚Ä¶</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bundle <span class="nb">install</span>
</code></pre></div></div> <p>and check it has worked by running:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>gem list
</code></pre></div></div> <p>So, now all you have to do is to run‚Ä¶</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bundle <span class="nb">exec </span>jekyll serve
</code></pre></div></div> <p>which will give a server address that you can access your website locally.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Configuration file: /Users/aamirsohail/Documents/GitHub/sohaamir.github.io/_config.yml
To use retry middleware with Faraday v2.0+, <span class="nb">install</span> <span class="sb">`</span>faraday-retry<span class="sb">`</span> gem
            Source: /Users/aamirsohail/Documents/GitHub/sohaamir.github.io
       Destination: /Users/aamirsohail/Documents/GitHub/sohaamir.github.io/_site
 Incremental build: disabled. Enable with <span class="nt">--incremental</span>
      Generating... 
       Jekyll Feed: Generating feed <span class="k">for </span>posts
   GitHub Metadata: No GitHub API authentication could be found. Some fields may be missing or have incorrect data.
                    <span class="k">done in </span>6.073 seconds.
 Auto-regeneration: enabled <span class="k">for</span> <span class="s1">'/Users/aamirsohail/Documents/GitHub/sohaamir.github.io'</span>
    Server address: http://127.0.0.1:4000/
  Server running... press ctrl-c to stop.
</code></pre></div></div> <p>Importantly, this will update (after a few seconds) after any changes are saved on your local machine, without you needing to commit these changes to your repository. Wanted to change the size of your profile avatar but aren‚Äôt sure if it‚Äôs the correct size? Just paste the server address provided into your browser, make the changes, and refresh the page!</p> <h1 id="constructing-your-own-website">Constructing your own website</h1> <p>So, if all has gone smoothly ü§û you should now be able to open up the template page using bundle, which looks something like this:</p> <div style="text-align: center;"> <img src="/assets/img/posts/website_guide/academic_template.png" alt="Academic template" width="500" height="400"/> </div> <p><br/> Now you can actually go about personalizing your website üòä I won‚Äôt cover everything that I have done, simply because most of it is covered by the other guides linked above, but I will go over the basic structure of some of the changes that you can make, with some specific examples that have not been covered by the other guides.</p> <p><strong>Changing the colour of a toolbar icon</strong></p> <p>One aspect of the toolbar which I changed was the colour of the ORCID logo, which is black in it‚Äôs default setting. I actually wanted to have the official circular logo, but annoyingly I was unable to get it to work, so have settled on having the square logo. To make the colour change, all I had to do was to firstly copy this code into <code class="language-plaintext highlighter-rouge">_sass/_utilities.scss</code> directly below the last <code class="language-plaintext highlighter-rouge">/* social icons*/</code> entry.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  .ai-orcid,
  .ai-orcid-square <span class="o">{</span>
    color: <span class="nv">$orcid</span><span class="nt">-color</span><span class="p">;</span>
  <span class="o">}</span>
</code></pre></div></div> <p>I then went into <code class="language-plaintext highlighter-rouge">_sass/_variables.scss</code> and added an orcid brand with the respective colour.</p> <div style="text-align: center;"> <img src="/assets/img/posts/website_guide/orcid_colour.png" alt="orcid colour" width="400" height="500"/> </div> <p><br/> <strong>Adding a gif</strong></p> <p>The first thing which grabs people‚Äôs attention is the GIF of a brain (actually a GIF of my own White-matter nulled MPRAGE T1). To add a GIF, simply using the following code:</p> <div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;div</span> <span class="na">style=</span><span class="s">"float: right; margin-left: 10px;"</span><span class="nt">&gt;</span>
  <span class="nt">&lt;img</span> <span class="na">src=</span><span class="s">"/path/to/your/gif/here"</span> <span class="na">alt=</span><span class="s">"Brain GIF"</span> <span class="na">width=</span><span class="s">"x"</span> <span class="na">height=</span><span class="s">"y"</span><span class="nt">&gt;</span>
<span class="nt">&lt;/div&gt;</span>
</code></pre></div></div> <p>And voila, you have your very own GIF!</p> <div style="display: flex; justify-content: center; align-items: center;"> <img src="/assets/img/posts/website_guide/brain_3_planes.gif" alt="Brain planes GIF" width="800" height="250"/> </div> <p><br/> <strong>Adding a Google Map</strong></p> <p>You may want to add a Google Map to demonstrate your current working address. To do so:</p> <ul> <li>Firstly find your location on Google maps,</li> <li>Click the ‚Äòshare‚Äô button across from the ‚ÄòDirections‚Äô button</li> <li>Select the ‚ÄòEmbed a map‚Äô tab and copy the HTML code</li> </ul> <div style="display: flex; justify-content: center; align-items: center;"> <img src="/assets/img/posts/website_guide/chbh_embed.png" alt="CHBH embed" width="600" height="600"/> </div> <ul> <li>Finally, just add the HTML code into the template:</li> </ul> <div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;iframe</span>
  <span class="na">src=</span><span class="s">"https://www.google.com/maps/embed?pb=!1m14!1m8!1m3!1d9725.651522662583!2d-1.9272804!3d52.4535496!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x4870bde470f7c04d%3A0x583b0469e1755681!2sCentre%20for%20Human%20Brain%20Health!5e0!3m2!1sen!2suk!4v1695917516555!5m2!1sen!2suk"</span> <span class="na">width=</span><span class="s">"850"</span> <span class="na">height=</span><span class="s">"450"</span> <span class="na">style=</span><span class="s">"border:0;"</span> <span class="na">allowfullscreen=</span><span class="s">""</span> <span class="na">loading=</span><span class="s">"lazy"</span> <span class="na">referrerpolicy=</span><span class="s">"no-referrer-when-downgrade"</span><span class="nt">&gt;&lt;/iframe&gt;</span>  
<span class="nt">&lt;br&gt;</span>
</code></pre></div></div> <p><br/> <strong>Adding your CV</strong></p> <p>In the tabs section at the top of your website, there is one for your ‚ÄòCV‚Äô. The default version I believe is to have your CV formatted into the website as any other post. However, we often put a lot of effort into our CV‚Äôs and would prefer to have the electronic version available. Thanksfully, this is easy to do.</p> <p>Firstly, if you go to <code class="language-plaintext highlighter-rouge">_data/navigation.yml</code> you can see all of the tabs that are defaulted in the website. To add your own CV and to have it open when opening the ‚ÄòCV‚Äô tab, you need to firstly upload your CV to the <code class="language-plaintext highlighter-rouge">files</code> subfolder. You then need to modify the <code class="language-plaintext highlighter-rouge">navigation.yml</code> file to tell it that you want to open up your CV. You can do this by writing the following for that section:</p> <div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  - title: "CV"
    url: /files/your_example.cv.pdf
</code></pre></div></div> <p>Importantly, this file can be used to change (or remove various tabs which aren‚Äôt relevant). For example, I decided to rename ‚ÄòPortfolio‚Äô to ‚ÄòResearch‚Äô and to comment out some tabs which aren‚Äôt relevant.</p> <div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code>main:
  - title: "Research"
    url: /portfolio/

 # - title: "Publications"
 #   url: /publications/

  - title: "Blog Posts"
    url: /year-archive/

  - title: "CV"
    url: /files/academic_cv.pdf

 # - title: "Talks"
 #   url: /talks/    

 # - title: "Teaching"
 #   url: /teaching/    
    
 # - title: "Guide"
 #   url: /markdown/
</code></pre></div></div> <p><br/> <strong>Changing your favicon</strong></p> <p>What on earth is a favicon? Isn‚Äôt that some type of Pokemon? Well, have you ever noticed in your browser, that there is often a little icon in the tab for each website? Well, that is called a favicon. It probably won‚Äôt be recognised by the visitors to your website, but I think changing the favicon to something more personalized is a nice touch. Here is how you can do it.</p> <p>Firstly, you need to find an image (preferably with no background). You then need to use a favicon generator (I used <a href="https://realfavicongenerator.net/">realfavicongenerator.net</a>). It demos what your favicon will look like on your website which can be handy, not least because if there is a background, it will show up.</p> <div style="text-align: center;"> <img src="/assets/img/posts/website_guide/favicon_website.png" alt="favicon website" width="600" height="300"/> </div> <p><br/> Scrolling down to the bottom of that page, you can then generate your favicon package. You can then extract it to folder called <code class="language-plaintext highlighter-rouge">favicon</code> in the <code class="language-plaintext highlighter-rouge">/assets/img</code> folder of your repository. Then open up <code class="language-plaintext highlighter-rouge">_includes/head/custom.html</code>and copy the following code:</p> <div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">&lt;!-- start custom head snippets --&gt;</span>

<span class="nt">&lt;link</span> <span class="na">rel=</span><span class="s">"apple-touch-icon"</span> <span class="na">sizes=</span><span class="s">"180x180"</span> <span class="na">href=</span><span class="s">"/assets/img/favicon/apple-touch-icon.png?v=M44lzPylqQ"</span><span class="nt">&gt;</span>
<span class="nt">&lt;link</span> <span class="na">rel=</span><span class="s">"icon"</span> <span class="na">type=</span><span class="s">"image/png"</span> <span class="na">sizes=</span><span class="s">"32x32"</span> <span class="na">href=</span><span class="s">"/assets/img/favicon/favicon-32x32.png?v=M44lzPylqQ"</span><span class="nt">&gt;</span>
<span class="nt">&lt;link</span> <span class="na">rel=</span><span class="s">"icon"</span> <span class="na">type=</span><span class="s">"image/png"</span> <span class="na">sizes=</span><span class="s">"16x16"</span> <span class="na">href=</span><span class="s">"/assets/img/favicon/favicon-16x16.png?v=M44lzPylqQ"</span><span class="nt">&gt;</span>
<span class="nt">&lt;link</span> <span class="na">rel=</span><span class="s">"manifest"</span> <span class="na">href=</span><span class="s">"/assets/img/favicon/site.webmanifest?v=M44lzPylqQ"</span><span class="nt">&gt;</span>
<span class="nt">&lt;link</span> <span class="na">rel=</span><span class="s">"mask-icon"</span> <span class="na">href=</span><span class="s">"/assets/img/favicon/safari-pinned-tab.svg?v=M44lzPylqQ"</span> <span class="na">color=</span><span class="s">"#5bbad5"</span><span class="nt">&gt;</span>
<span class="nt">&lt;meta</span> <span class="na">name=</span><span class="s">"msapplication-TileColor"</span> <span class="na">content=</span><span class="s">"#da532c"</span><span class="nt">&gt;</span>
<span class="nt">&lt;meta</span> <span class="na">name=</span><span class="s">"theme-color"</span> <span class="na">content=</span><span class="s">"#ffffff"</span><span class="nt">&gt;</span>

<span class="nt">&lt;link</span> <span class="na">rel=</span><span class="s">"stylesheet"</span> <span class="na">href=</span><span class="s">"/assets/css/academicons.css"</span><span class="nt">/&gt;</span>

...
<span class="c">&lt;!-- end custom head snippets --&gt;</span>
</code></pre></div></div> <p>And that‚Äôs it! You should have a new favicon, the image that you selected earlier. Was it worth it? Probably. <br/></p> <div style="text-align: center;"> <img src="/assets/img/posts/website_guide/favicon_tab.png" alt="favicon tab" width="400" height="40"/> </div> <p><br/><br/> <strong>Contact Forms</strong></p> <p>The final guide that I will cover is adding a contact form which people can actually use to contact an email address. To do this, you need a server to process the HTML forms for us. I ended up using <a href="https://formspree.io/">Formspree</a> but there are others available. Through Formspree, once you create an account and a form, it will generate some HTML code for you to paste in your website. For me, the code looked like this:</p> <div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">&lt;!-- modify this form HTML and place wherever you want your form --&gt;</span>
<span class="nt">&lt;form</span>
  <span class="na">action=</span><span class="s">"https://formspree.io/f/xpzgowwz"</span>
  <span class="na">method=</span><span class="s">"POST"</span>
<span class="nt">&gt;</span>
  <span class="nt">&lt;label&gt;</span>
    Your email:
    <span class="nt">&lt;input</span> <span class="na">type=</span><span class="s">"email"</span> <span class="na">name=</span><span class="s">"email"</span><span class="nt">&gt;</span>
  <span class="nt">&lt;/label&gt;</span>
  <span class="nt">&lt;label&gt;</span>
    Your message:
    <span class="nt">&lt;textarea</span> <span class="na">name=</span><span class="s">"message"</span><span class="nt">&gt;&lt;/textarea&gt;</span>
  <span class="nt">&lt;/label&gt;</span>
  <span class="c">&lt;!-- your other form fields go here --&gt;</span>
  <span class="nt">&lt;button</span> <span class="na">type=</span><span class="s">"submit"</span><span class="nt">&gt;</span>Send<span class="nt">&lt;/button&gt;</span>
<span class="nt">&lt;/form&gt;</span>
</code></pre></div></div> <p>Whilst the action URL will be different, everything else should be the same. All you have to do now is to copy this code into whichever page you want the form to be presented and that‚Äôs it! The only additional change I made was to add a third box where the person‚Äôs name can be recorded. So, my form looks like this:</p> <div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;form</span>
  <span class="na">action=</span><span class="s">"https://formspree.io/f/xpzgowwz"</span>
  <span class="na">method=</span><span class="s">"POST"</span>
<span class="nt">&gt;</span>
  <span class="nt">&lt;label&gt;</span>
    Your name:
    <span class="nt">&lt;input</span> <span class="na">type=</span><span class="s">"text"</span> <span class="na">name=</span><span class="s">"name"</span><span class="nt">&gt;</span>
  <span class="nt">&lt;/label&gt;</span>
  <span class="nt">&lt;label&gt;</span>
    Your email:
    <span class="nt">&lt;input</span> <span class="na">type=</span><span class="s">"email"</span> <span class="na">name=</span><span class="s">"email"</span><span class="nt">&gt;</span>
  <span class="nt">&lt;/label&gt;</span>
  <span class="nt">&lt;label&gt;</span>
    Your message:
    <span class="nt">&lt;textarea</span> <span class="na">name=</span><span class="s">"message"</span><span class="nt">&gt;&lt;/textarea&gt;</span>
  <span class="nt">&lt;/label&gt;</span>
  <span class="nt">&lt;button</span> <span class="na">type=</span><span class="s">"submit"</span><span class="nt">&gt;</span>Send message<span class="nt">&lt;/button&gt;</span>
<span class="nt">&lt;/form&gt;</span>
</code></pre></div></div> <p>Subsequently, whenever someone fills out my form, I get an email with the following:</p> <div style="text-align: center;"> <img src="/assets/img/posts/website_guide/formspree_email.png" alt="formspree email" width="500" height="300"/> </div> <p><strong>Other useful tips already covered in other guides</strong></p> <p>There are a few more changes that I made, but using guides that already exist. I would highly recommend checking them out if you would like to do the same. These are listed above, but one specific aspect that I would highlight is with changing profile avatar and the size of your name. If you want to change the size/shape of your profile avatar and the size of your name immediately below, see <a href="https://www.cross-validated.com/Personal-website-with-Minimal-Mistakes-Jekyll-Theme-HOWTO-Part-II/">Personal Website with Minimal Mistakes Jekyll Theme HOWTO</a> by Katerina Bosko. There are also many other useful customizations covered on her page. <br/></p> <h1 id="committing-your-changes-with-git">Committing your changes with git</h1> <p>Ok, so you‚Äôve been hard at work making all of these customizations, you‚Äôve checked through bundle that you are happy with these changes, and would now like to make them ‚Äòofficial‚Äô so-to-speak. This is very simple to do using <a href="https://git-scm.com/">Git</a>. Again, the fact that you have been using GitHub should mean that Git is no stranger, but just for convienience, Git is the fundamental tool for version control, which GitHub uses to provide remote hosting for Git repositories. So, because you have made the changes on your local machine, you can use Git to ‚Äòcommit‚Äô these changes to the repository hosted on GitHub. You just need to run the following commands from your website‚Äôs root:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git status
git add <span class="nb">.</span>
git commit <span class="nt">-m</span> <span class="s1">'describe changes made here'</span>
git push origin
</code></pre></div></div> <p>And that‚Äôs it! Your GitHub repository should then update with your local changes (it may take a minute). You can then see the latest version of your website by selecting your repository on your GitHub page, choosing the ‚ÄòActions‚Äô tab, clicking on the most recent deployment and clicking your github.io link.</p> <div style="text-align: center;"> <img src="/assets/img/posts/website_guide/github_screenshot.png" alt="GitHub screenshot" width="550" height="300"/> </div> <p><br/></p> <p><em>N.B If you are wondering why this guide is for the academicpages theme when I am currently using the al-folio theme, then yes I ended up changing my mind after initially making my website in the former ü§¶</em></p> <p>Image credits:</p> <p class="small-text"> Bruce Almighty GIF: Tom Shadyac, et al. ¬© BRUCE ALMIGHTY. USA, 2003. GIF provided by <a href="https://tenor.com/en-GB/view/bruce-almighty-jim-carrey-type-typing-fast-gif-4271405">Tenor</a> </p> <p class="small-text"> Screenshots: <a href="https://lakemper.eu/">Michael Schlottke-Lakemper</a>, <a href="https://jayrobwilliams.com/">Rob Williams</a>, <a href="https://github.com/academicpages/academicpages.github.io">Academic Pages</a> ¬© 2016 Michael Rose and released under the MIT License. </p>]]></content><author><name></name></author><category term="tutorials"/><category term="programming,"/><category term="website"/><category term="design"/><summary type="html"><![CDATA[How to set up a website using Jekyll and GitHub Pages]]></summary></entry><entry><title type="html">Once a CINNer, always a CINNer</title><link href="https://sohaamir.github.io/blog/2023/cinn_goodbye/" rel="alternate" type="text/html" title="Once a CINNer, always a CINNer"/><published>2023-09-28T13:56:00+00:00</published><updated>2023-09-28T13:56:00+00:00</updated><id>https://sohaamir.github.io/blog/2023/cinn_goodbye</id><content type="html" xml:base="https://sohaamir.github.io/blog/2023/cinn_goodbye/"><![CDATA[<p>I am retrospectively writing this from the CHBH üåö but I thought I would write a quick post saying goodbye to all the CINNers at the University of Reading who supported me over the past two-and-a-half-years. I honestly learned so much and am extremely grateful for everything! I look forward to keeping you updated with my PhD and getting our projects published! üéÜ</p> <p>Best,<br/> Aamir <br/> <br/></p> <div style="text-align: center;"> <img src="/assets/img/posts/cinn_goodbye/cinn_goodbye.jpeg" alt="CINN Goodbye" width="700" height="320"/> </div> <p><br/> <em>People (clockwise from left to right): Phoenix Byrne, Brendan Williams, Gabriella Rossetti (hidden üò¢), Zola Dean, Charlenne Ordonez, Anastasiya Savchenko, Anastasia Christakou, Me, Rich Harrison, Claudia Rodriguez-Sobstel.</em></p>]]></content><author><name></name></author><category term="blogs"/><category term="cinn,"/><category term="goodbye"/><summary type="html"><![CDATA[Saying goodbye to CINN after 2 and a half years!]]></summary></entry></feed>